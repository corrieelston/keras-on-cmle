{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Keras Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a version of our model that integrates Keras into the customer estimator from tf.contrib.learn we can proceed to add in additional code required to train this model on Google Cloud Machine Learning Engine (CMLE).  There are a relatively small number of changes required to get a big uplift in functionality together with the ability to run locally or deploy to CMLE with equal ease from the command line.  Changes will be explained as the solution progresses.\n",
    "\n",
    "At a high level we do two things:\n",
    "\n",
    "* Change the mechanism for accessing training/test data from reading directly from local files to reading files from Google Cloud Storage (GCS).\n",
    "* Encapsulate the model and additional requirements into an Experiment which in turn managed by a learn_runner from tf.contrib.learn.  Experiment has the functionality required to train and evaluate a model in a distributed environment, including checkpointing progress, reporting summaries that can be consumed by TensorBoard, etc.  In turn learn_runner is a utility that helps run and tune an Experiment.\n",
    "\n",
    "One change from usual practice called out in advance is that usually TensorFlow modelling, especially for CMLE, the model is placed in one file and the associated code to run it is placed in another.  These are usually called model and task.  This is a sensible separation of concerns because it makes it easier to swap models easily.  However, for the purposes of this tutorial I'm combining both into a single notebook/file for convenience.\n",
    "\n",
    "When you're happy with this proceed to the [next notebook](6-distributed-keras.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell deletes a local directory used when this model is trained locally (i.e. by running this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf abalone_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import six\n",
    "from six.moves import urllib\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section follows standard TensorFlow practices for production grade machine learning.  It defines how to decode a line from a CSV file (together with sensible defaults), instantiates a queue of filenames (in this case we have one), then connects the content of the CSV file to a batching mechanism (that either shuffles the data - usual practice in the case of training - or not - usual practice in the case of evaluation) that encapsulates the details of reading the data, buffering data for training, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['length', 'diameter', 'height', 'whole_weight', 'shucked_weight',\n",
    "               'viscera_weight', 'shell_weight', 'num_rings']\n",
    "CSV_COLUMN_DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "PREDICTED_COLUMN = 'num_rings'\n",
    "INPUT_COLUMNS = [\n",
    "    tf.feature_column.numeric_column('length'),\n",
    "    tf.feature_column.numeric_column('diameter'),\n",
    "    tf.feature_column.numeric_column('height'),\n",
    "    tf.feature_column.numeric_column('whole_weight'),\n",
    "    tf.feature_column.numeric_column('shucked_weight'),\n",
    "    tf.feature_column.numeric_column('viscera_weight'),\n",
    "    tf.feature_column.numeric_column('shell_weight'),\n",
    "]\n",
    "\n",
    "UNUSED_COLUMNS = set(CSV_COLUMNS) - {col.name for col in INPUT_COLUMNS} - {PREDICTED_COLUMN}\n",
    "\n",
    "def parse_csv(rows_string_tensor):\n",
    "  columns = tf.decode_csv(rows_string_tensor, record_defaults=CSV_COLUMN_DEFAULTS)\n",
    "  features = dict(zip(CSV_COLUMNS, columns))\n",
    "\n",
    "  for col in UNUSED_COLUMNS:\n",
    "    features.pop(col)\n",
    "\n",
    "  for key, value in six.iteritems(features):\n",
    "    features[key] = tf.expand_dims(features[key], -1)\n",
    "  return features\n",
    "\n",
    "def generate_input_fn(filenames,\n",
    "                      num_epochs=None,\n",
    "                      shuffle=True,\n",
    "                      skip_header_lines=0,\n",
    "                      batch_size=64):\n",
    "  \n",
    "  filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs, shuffle=shuffle)\n",
    "  reader = tf.TextLineReader(skip_header_lines=skip_header_lines)\n",
    "\n",
    "  _, rows = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "\n",
    "  features = parse_csv(rows)\n",
    "\n",
    "  if shuffle:\n",
    "    features = tf.train.shuffle_batch(\n",
    "        features,\n",
    "        batch_size,\n",
    "        min_after_dequeue=2 * batch_size + 1,\n",
    "        capacity=batch_size * 10,\n",
    "        num_threads=multiprocessing.cpu_count(),\n",
    "        enqueue_many=True,\n",
    "        allow_smaller_final_batch=True\n",
    "    )\n",
    "  else:\n",
    "    features = tf.train.batch(\n",
    "        features,\n",
    "        batch_size,\n",
    "        capacity=batch_size * 10,\n",
    "        num_threads=multiprocessing.cpu_count(),\n",
    "        enqueue_many=True,\n",
    "        allow_smaller_final_batch=True\n",
    "    )\n",
    "\n",
    "  return features, features.pop(PREDICTED_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras.python.keras.layers import Dense\n",
    "\n",
    "def generate_model_fn(learning_rate):\n",
    "    \n",
    "    def _model_fn(mode, features, labels):\n",
    "\n",
    "        (length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight) = INPUT_COLUMNS\n",
    "\n",
    "        transformed_columns = [\n",
    "            length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight\n",
    "        ]\n",
    "\n",
    "        inputs = tf.feature_column.input_layer(features, transformed_columns)\n",
    "\n",
    "        first_hidden_layer = Dense(10, activation='relu')(inputs)\n",
    "        second_hidden_layer = Dense(10, activation='relu')(first_hidden_layer)\n",
    "        output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "\n",
    "        if mode in (Modes.PREDICT, Modes.EVAL):\n",
    "          predictions = tf.reshape(output_layer, [-1])\n",
    "          predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "        if mode in (Modes.TRAIN, Modes.EVAL):\n",
    "          loss = tf.losses.mean_squared_error(labels, output_layer)\n",
    "\n",
    "        if mode == Modes.TRAIN:\n",
    "          train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=learning_rate,\n",
    "            optimizer=\"SGD\")\n",
    "        \n",
    "        if mode == Modes.TRAIN:\n",
    "          return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "        if mode == Modes.EVAL:\n",
    "          eval_metric_ops = {\n",
    "              \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "                  tf.cast(labels, tf.float32), predictions)\n",
    "          }\n",
    "          return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "        \n",
    "        if mode == Modes.PREDICT:\n",
    "          export_outputs = {\n",
    "              'prediction': tf.estimator.export.RegressionOutput(predictions)\n",
    "          }\n",
    "          return tf.estimator.EstimatorSpec(\n",
    "              mode, predictions=predictions_dict, export_outputs=export_outputs)\n",
    "    \n",
    "    return _model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section encapsulates producing the Experiment.  Note that this follows standard practice for tf.contrib.learn of providing data via input_fn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_experiment_fn(**experiment_args):  \n",
    "  \n",
    "  def _experiment_fn(run_config, hparams):\n",
    "\n",
    "    train_input = lambda: generate_input_fn(\n",
    "      hparams.train_files,\n",
    "      num_epochs=hparams.num_epochs,\n",
    "      batch_size=hparams.train_batch_size,\n",
    "    )\n",
    "\n",
    "    test_input = lambda: generate_input_fn(\n",
    "      hparams.eval_files,\n",
    "      shuffle=False\n",
    "    )\n",
    "\n",
    "    return tf.contrib.learn.Experiment(\n",
    "        tf.estimator.Estimator(\n",
    "            generate_model_fn(learning_rate=hparams.learning_rate),\n",
    "            config=run_config\n",
    "        ),\n",
    "        train_input_fn=train_input,\n",
    "        eval_input_fn=test_input,\n",
    "        **experiment_args\n",
    "    )\n",
    "  \n",
    "  return _experiment_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def example_serving_input_fn():\n",
    "  \"\"\"Build the serving inputs.\"\"\"\n",
    "  example_bytestring = tf.placeholder(\n",
    "      shape=[None],\n",
    "      dtype=tf.string,\n",
    "  )\n",
    "  features = tf.parse_example(\n",
    "      example_bytestring,\n",
    "      tf.feature_column.make_parse_example_spec(INPUT_COLUMNS)\n",
    "  )\n",
    "  return tf.estimator.export.ServingInputReceiver(\n",
    "      features, {'example_proto': example_bytestring})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section adds a main method to our code because when we come to run this on CMLE we will change from Datalab to script files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'abalone_output', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd72bb1dc10>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_session_config': None}\n",
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into abalone_output/model.ckpt.\n",
      "INFO:tensorflow:loss = 50.2422, step = 1\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-20:09:23\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-20:09:25\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 116.533, rmse = 10.7951\n",
      "INFO:tensorflow:Validation (step 1): loss = 116.533, global_step = 1, rmse = 10.7951\n",
      "INFO:tensorflow:global_step/sec: 46.4482\n",
      "INFO:tensorflow:loss = 19.0157, step = 101 (2.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 597.836\n",
      "INFO:tensorflow:loss = 7.57836, step = 201 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.129\n",
      "INFO:tensorflow:loss = 1.32549, step = 301 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.548\n",
      "INFO:tensorflow:loss = 0.782242, step = 401 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 611.506\n",
      "INFO:tensorflow:loss = 4.80393, step = 501 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.515\n",
      "INFO:tensorflow:loss = 0.461195, step = 601 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.973\n",
      "INFO:tensorflow:loss = 0.213797, step = 701 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.008\n",
      "INFO:tensorflow:loss = 1.33851, step = 801 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.778\n",
      "INFO:tensorflow:loss = 25.9228, step = 901 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 590.475\n",
      "INFO:tensorflow:loss = 53.2385, step = 1001 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.152\n",
      "INFO:tensorflow:loss = 0.0280462, step = 1101 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.32\n",
      "INFO:tensorflow:loss = 0.566131, step = 1201 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.076\n",
      "INFO:tensorflow:loss = 95.5419, step = 1301 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 583.084\n",
      "INFO:tensorflow:loss = 0.000793931, step = 1401 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.218\n",
      "INFO:tensorflow:loss = 0.0737695, step = 1501 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.8\n",
      "INFO:tensorflow:loss = 0.101973, step = 1601 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.214\n",
      "INFO:tensorflow:loss = 53.6897, step = 1701 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.219\n",
      "INFO:tensorflow:loss = 10.9894, step = 1801 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.478\n",
      "INFO:tensorflow:loss = 0.750774, step = 1901 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.801\n",
      "INFO:tensorflow:loss = 4.31166, step = 2001 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.337\n",
      "INFO:tensorflow:loss = 1.68143, step = 2101 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.243\n",
      "INFO:tensorflow:loss = 4.9261, step = 2201 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.955\n",
      "INFO:tensorflow:loss = 0.23877, step = 2301 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.58\n",
      "INFO:tensorflow:loss = 2.86915, step = 2401 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.315\n",
      "INFO:tensorflow:loss = 0.479926, step = 2501 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.553\n",
      "INFO:tensorflow:loss = 0.418186, step = 2601 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.426\n",
      "INFO:tensorflow:loss = 16.793, step = 2701 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.683\n",
      "INFO:tensorflow:loss = 4.62109, step = 2801 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.087\n",
      "INFO:tensorflow:loss = 7.90221, step = 2901 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.79\n",
      "INFO:tensorflow:loss = 0.00846821, step = 3001 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.984\n",
      "INFO:tensorflow:loss = 2.65141, step = 3101 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.175\n",
      "INFO:tensorflow:loss = 5.08143, step = 3201 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.95\n",
      "INFO:tensorflow:loss = 0.393982, step = 3301 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.093\n",
      "INFO:tensorflow:loss = 0.245855, step = 3401 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.013\n",
      "INFO:tensorflow:loss = 2.29022, step = 3501 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.3\n",
      "INFO:tensorflow:loss = 4.11349, step = 3601 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.022\n",
      "INFO:tensorflow:loss = 0.0650124, step = 3701 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 594.597\n",
      "INFO:tensorflow:loss = 11.2837, step = 3801 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.594\n",
      "INFO:tensorflow:loss = 0.253782, step = 3901 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.149\n",
      "INFO:tensorflow:loss = 3.25756, step = 4001 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.734\n",
      "INFO:tensorflow:loss = 0.0323534, step = 4101 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 597.304\n",
      "INFO:tensorflow:loss = 3.26839, step = 4201 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.631\n",
      "INFO:tensorflow:loss = 1.61379, step = 4301 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.163\n",
      "INFO:tensorflow:loss = 1.40315, step = 4401 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 548.592\n",
      "INFO:tensorflow:loss = 0.342284, step = 4501 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.077\n",
      "INFO:tensorflow:loss = 0.61453, step = 4601 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.117\n",
      "INFO:tensorflow:loss = 0.0519939, step = 4701 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.991\n",
      "INFO:tensorflow:loss = 41.2969, step = 4801 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.451\n",
      "INFO:tensorflow:loss = 0.250531, step = 4901 (0.163 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into abalone_output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.91908.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-20:09:34\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-20:09:36\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.88718, rmse = 2.42635\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: abalone_output/export/Servo/1501704576/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "from tensorflow.contrib.learn.python.learn.utils import (\n",
    "    saved_model_export_utils)\n",
    "from tensorflow.contrib.training.python.training import hparam\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Input Arguments\n",
    "    parser.add_argument(\n",
    "        '--train-files',\n",
    "        help='GCS or local paths to training data',\n",
    "        nargs='+',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--num-epochs',\n",
    "        help=\"\"\"\\\n",
    "        Maximum number of training data epochs on which to train.\n",
    "        If both --max-steps and --num-epochs are specified,\n",
    "        the training job will run for --max-steps or --num-epochs,\n",
    "        whichever occurs first. If unspecified will run for --max-steps.\\\n",
    "        \"\"\",\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train-batch-size',\n",
    "        help='Batch size for training steps',\n",
    "        type=int,\n",
    "        default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-batch-size',\n",
    "        help='Batch size for evaluation steps',\n",
    "        type=int,\n",
    "        default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-files',\n",
    "        help='GCS or local paths to evaluation data',\n",
    "        nargs='+',\n",
    "        required=True\n",
    "    )\n",
    "    # Training arguments\n",
    "    parser.add_argument(\n",
    "        '--learning-rate',\n",
    "        help='Learning rate for the optimizer',\n",
    "        default=0.001,\n",
    "        type=float\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help='GCS location to write checkpoints and export models',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--verbosity',\n",
    "        choices=[\n",
    "            'DEBUG',\n",
    "            'ERROR',\n",
    "            'FATAL',\n",
    "            'INFO',\n",
    "            'WARN'\n",
    "        ],\n",
    "        default='INFO',\n",
    "        help='Set logging verbosity'\n",
    "    )\n",
    "    # Experiment arguments\n",
    "    parser.add_argument(\n",
    "        '--eval-delay-secs',\n",
    "        help='How long to wait before running first evaluation',\n",
    "        default=10,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--min-eval-frequency',\n",
    "        help='Minimum number of training steps between evaluations',\n",
    "        default=1,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train-steps',\n",
    "        help=\"\"\"\\\n",
    "        Steps to run the training job for. If --num-epochs is not specified,\n",
    "        this must be. Otherwise the training job will run indefinitely.\\\n",
    "        \"\"\",\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-steps',\n",
    "        help=\"\"\"\\\n",
    "        Number of steps to run evalution for at each checkpoint.\n",
    "        If unspecified will run until the input from --eval-files is exhausted\n",
    "        \"\"\",\n",
    "        default=None,\n",
    "        type=int\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args([\n",
    "        '--train-files', 'gs://smiling-beaming-abalone/abalone_train.csv',\n",
    "        '--eval-files', 'gs://smiling-beaming-abalone/abalone_test.csv',\n",
    "        '--job-dir', 'abalone_output',\n",
    "        '--train-steps', '5000',\n",
    "        '--eval-steps', '100'\n",
    "      ])\n",
    "    \n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    # Set python level verbosity\n",
    "    tf.logging.set_verbosity(args.verbosity)\n",
    "    # Set C++ Graph Execution level verbosity\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = str(\n",
    "        tf.logging.__dict__[args.verbosity] / 10)\n",
    "\n",
    "    # Run the training job\n",
    "    # learn_runner pulls configuration information from environment\n",
    "    # variables using tf.learn.RunConfig and uses this configuration\n",
    "    # to conditionally execute Experiment, or param server code\n",
    "    learn_runner.run(\n",
    "        generate_experiment_fn(\n",
    "            min_eval_frequency=args.min_eval_frequency,\n",
    "            eval_delay_secs=args.eval_delay_secs,\n",
    "            train_steps=args.train_steps,\n",
    "            eval_steps=args.eval_steps,\n",
    "            export_strategies=[saved_model_export_utils.make_export_strategy(\n",
    "                example_serving_input_fn,\n",
    "                exports_to_keep=1\n",
    "            )]\n",
    "        ),\n",
    "        run_config=tf.contrib.learn.RunConfig(model_dir=args.job_dir),\n",
    "        hparams=hparam.HParams(**args.__dict__)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
