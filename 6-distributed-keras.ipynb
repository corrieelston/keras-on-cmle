{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Keras Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to do a little Datalab-fu to get things running on CMLE.  The essence is that once you get to the point of a working, production-grade model you'll flip from Datalab to coding in Python script files because CMLE requires this (you need to supply a python package and module to the gcloud CLI.  Personally, what I do is once I have the code in the previous notebook running in Datalab I download the script as a Python script file and switch to my editor of choice (usually vi or emacs because I don't have much left to do in essence).\n",
    "\n",
    "However, what I'll do here is create the required files via Datalab:\n",
    "\n",
    "1. Some cleanup - in case you are running this notebook multiple times - by deleting the local directories for the Python package and the model training output.\n",
    "2. Create a directory for our Python package (called trainer).\n",
    "3. Create an (empty) __init__.py file in the trainer directory (which can be empty but serves to designate the directory as a package).\n",
    "4. Take the exact same code as the last notebook (with the exception that we'll read all the arguments from the command line - in the last notebook we hardcoded some defaults) and save it in a file called task in the trainer directory.\n",
    "\n",
    "Then we can run train and evaluate the mode locally and on CMLE proper.\n",
    "\n",
    "To run locally we execute the following.\n",
    "\n",
    "```\n",
    "gcloud ml-engine local train --package-path trainer \\\n",
    "   --module-name trainer.task \\\n",
    "   -- \\\n",
    "   --train-files gs://smiling-beaming-abalone/abalone_train.csv \\\n",
    "   --eval-files gs://smiling-beaming-abalone/abalone_test.csv \\\n",
    "   --job-dir abalone_output \\\n",
    "   --train-steps 5000 \\\n",
    "   --eval-steps 100\n",
    "```\n",
    "\n",
    "Which is self explanatory.  To run on CMLE we execute the following.\n",
    "\n",
    "```\n",
    "!gcloud ml-engine jobs submit training abalone_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --stream-logs \\\n",
    "  --scale-tier STANDARD_1 \\\n",
    "  --runtime-version 1.2 \\\n",
    "  --job-dir gs://smiling-beaming-abalone/abalone_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --module-name trainer.task \\\n",
    "  --package-path trainer \\\n",
    "  --region us-central1 \\\n",
    "  -- \\\n",
    "  --train-files gs://smiling-beaming-abalone/abalone_train.csv \\\n",
    "  --eval-files gs://smiling-beaming-abalone/abalone_test.csv \\\n",
    "  --train-steps 5000 \\\n",
    "  --eval-steps 100\n",
    "```\n",
    "\n",
    "The only difference in this case is that we submit the job to the CMLE managed service and we choose a scale tier to indicate the amount of compute horsepower we want to throw at the problem.  In this case, we're using STANDARD_1 which gives us a master, three workers and three parameter servers (all CPU-based) which is teh smallest, standard footprint that gives us distributed training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some housekeeping, we need to delete the output folder we use locally between runs (in case you run this notebook multiple times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf trainer && rm -rf abalone_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!touch trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer/task.py\n",
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import multiprocessing\n",
    "\n",
    "import six\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense\n",
    "\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "from tensorflow.contrib.learn.python.learn.utils import (saved_model_export_utils)\n",
    "from tensorflow.contrib.training.python.training import hparam\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "CSV_COLUMNS = [\n",
    "    'length', 'diameter', 'height', 'whole_weight', 'shucked_weight',\n",
    "    'viscera_weight', 'shell_weight', 'num_rings'\n",
    "]\n",
    "CSV_COLUMN_DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "PREDICTED_COLUMN = 'num_rings'\n",
    "INPUT_COLUMNS = [\n",
    "    tf.feature_column.numeric_column('length'),\n",
    "    tf.feature_column.numeric_column('diameter'),\n",
    "    tf.feature_column.numeric_column('height'),\n",
    "    tf.feature_column.numeric_column('whole_weight'),\n",
    "    tf.feature_column.numeric_column('shucked_weight'),\n",
    "    tf.feature_column.numeric_column('viscera_weight'),\n",
    "    tf.feature_column.numeric_column('shell_weight'),\n",
    "]\n",
    "\n",
    "UNUSED_COLUMNS = set(CSV_COLUMNS) - {col.name for col in INPUT_COLUMNS} - {PREDICTED_COLUMN}\n",
    "\n",
    "def parse_csv(rows_string_tensor):\n",
    "    columns = tf.decode_csv(rows_string_tensor, record_defaults=CSV_COLUMN_DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMNS, columns))\n",
    "\n",
    "    for col in UNUSED_COLUMNS:\n",
    "        features.pop(col)\n",
    "\n",
    "    for key, value in six.iteritems(features):\n",
    "        features[key] = tf.expand_dims(features[key], -1)\n",
    "    return features\n",
    "\n",
    "def generate_input_fn(filenames,\n",
    "                      num_epochs=None,\n",
    "                      shuffle=True,\n",
    "                      skip_header_lines=0,\n",
    "                      batch_size=64):\n",
    "  \n",
    "    def _input_fn():\n",
    "  \n",
    "        filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs, shuffle=shuffle)\n",
    "        reader = tf.TextLineReader(skip_header_lines=skip_header_lines)\n",
    "\n",
    "        _, rows = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "\n",
    "        features = parse_csv(rows)\n",
    "\n",
    "        if shuffle:\n",
    "            features = tf.train.shuffle_batch(\n",
    "                features,\n",
    "                batch_size,\n",
    "                min_after_dequeue=2 * batch_size + 1,\n",
    "                capacity=batch_size * 10,\n",
    "                num_threads=multiprocessing.cpu_count(),\n",
    "                enqueue_many=True,\n",
    "                allow_smaller_final_batch=True\n",
    "            )\n",
    "        else:\n",
    "            features = tf.train.batch(\n",
    "                features,\n",
    "                batch_size,\n",
    "                capacity=batch_size * 10,\n",
    "                num_threads=multiprocessing.cpu_count(),\n",
    "                enqueue_many=True,\n",
    "                allow_smaller_final_batch=True\n",
    "            )\n",
    "\n",
    "        return features, features.pop(PREDICTED_COLUMN)\n",
    "  \n",
    "    return _input_fn\n",
    "\n",
    "def generate_model_fn(learning_rate):\n",
    "    \n",
    "    def _model_fn(mode, features, labels):\n",
    "\n",
    "        (length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight) = INPUT_COLUMNS\n",
    "\n",
    "        transformed_columns = [\n",
    "            length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight\n",
    "        ]\n",
    "\n",
    "        inputs = tf.feature_column.input_layer(features, transformed_columns)\n",
    "\n",
    "        first_hidden_layer = Dense(10, activation='relu')(inputs)\n",
    "        second_hidden_layer = Dense(10, activation='relu')(first_hidden_layer)\n",
    "        output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "\n",
    "        if mode in (Modes.PREDICT, Modes.EVAL):\n",
    "            predictions = tf.reshape(output_layer, [-1])\n",
    "            predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "        if mode in (Modes.TRAIN, Modes.EVAL):\n",
    "            loss = tf.losses.mean_squared_error(labels, output_layer)\n",
    "\n",
    "        if mode == Modes.TRAIN:\n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "                loss=loss,\n",
    "                global_step=tf.contrib.framework.get_global_step(),\n",
    "                learning_rate=learning_rate,\n",
    "                optimizer=\"SGD\")\n",
    "        \n",
    "        if mode == Modes.TRAIN:\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "        if mode == Modes.EVAL:\n",
    "            eval_metric_ops = {\n",
    "                \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "                    tf.cast(labels, tf.float32), predictions)\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "        \n",
    "        if mode == Modes.PREDICT:\n",
    "            export_outputs = {\n",
    "                'prediction': tf.estimator.export.RegressionOutput(predictions)\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, predictions=predictions_dict, export_outputs=export_outputs)\n",
    "    \n",
    "    return _model_fn\n",
    "\n",
    "def generate_experiment_fn(**experiment_args):  \n",
    "  \n",
    "    def _experiment_fn(run_config, hparams):\n",
    "\n",
    "        train_input = generate_input_fn(\n",
    "            hparams.train_files,\n",
    "            num_epochs=hparams.num_epochs,\n",
    "            batch_size=hparams.train_batch_size,\n",
    "        )\n",
    "\n",
    "        test_input = generate_input_fn(\n",
    "            hparams.eval_files,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        return tf.contrib.learn.Experiment(\n",
    "            tf.estimator.Estimator(\n",
    "                generate_model_fn(learning_rate=hparams.learning_rate),\n",
    "                config=run_config\n",
    "            ),\n",
    "            train_input_fn=train_input,\n",
    "            eval_input_fn=test_input,\n",
    "            **experiment_args\n",
    "        )\n",
    "\n",
    "    return _experiment_fn\n",
    "\n",
    "def example_serving_input_fn():\n",
    "    example_bytestring = tf.placeholder(\n",
    "        shape=[None],\n",
    "        dtype=tf.string,\n",
    "    )\n",
    "    features = tf.parse_example(\n",
    "        example_bytestring,\n",
    "        tf.feature_column.make_parse_example_spec(INPUT_COLUMNS)\n",
    "    )\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        features, {'example_proto': example_bytestring})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--train-files',\n",
    "        nargs='+',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--num-epochs',\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train-batch-size',\n",
    "        type=int,\n",
    "        default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-batch-size',\n",
    "        type=int,\n",
    "        default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-files',\n",
    "        nargs='+',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--learning-rate',\n",
    "        default=0.001,\n",
    "        type=float\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-delay-secs',\n",
    "        default=10,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--min-eval-frequency',\n",
    "        default=1,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train-steps',\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-steps',\n",
    "        default=None,\n",
    "        type=int\n",
    "    )\n",
    "\n",
    "    # For the purposes of running in a notebook hardcoding arguments\n",
    "    '''args = parser.parse_args([\n",
    "        '--train-files', 'gs://smiling-beaming-abalone/abalone_train.csv',\n",
    "        '--eval-files', 'gs://smiling-beaming-abalone/abalone_test.csv',\n",
    "        '--job-dir', 'abalone_output',\n",
    "        '--train-steps', '5000',\n",
    "        '--eval-steps', '100'\n",
    "      ])'''\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    learn_runner.run(\n",
    "        generate_experiment_fn(\n",
    "            min_eval_frequency=args.min_eval_frequency,\n",
    "            eval_delay_secs=args.eval_delay_secs,\n",
    "            train_steps=args.train_steps,\n",
    "            eval_steps=args.eval_steps,\n",
    "            export_strategies=[saved_model_export_utils.make_export_strategy(\n",
    "                example_serving_input_fn,\n",
    "                exports_to_keep=1\n",
    "            )]\n",
    "        ),\n",
    "        run_config=tf.contrib.learn.RunConfig(model_dir=args.job_dir),\n",
    "        hparams=hparam.HParams(**args.__dict__)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the code locally..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'abalone_output', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': u'cloud', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f495c6790d0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_session_config': None}\n",
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "2017-08-08 17:31:34.047644: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-08 17:31:34.047797: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-08 17:31:34.047811: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-08 17:31:34.047818: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-08 17:31:34.047825: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into abalone_output/model.ckpt.\n",
      "INFO:tensorflow:loss = 46.8618, step = 1\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-08-17:31:34\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-08-17:31:36\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 107.606, rmse = 10.3734\n",
      "INFO:tensorflow:Validation (step 1): loss = 107.606, global_step = 1, rmse = 10.3734\n",
      "INFO:tensorflow:global_step/sec: 43.0595\n",
      "INFO:tensorflow:loss = 8.24609, step = 101 (2.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.375\n",
      "INFO:tensorflow:loss = 0.361229, step = 201 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.506\n",
      "INFO:tensorflow:loss = 0.772758, step = 301 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.75\n",
      "INFO:tensorflow:loss = 1.00204, step = 401 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.233\n",
      "INFO:tensorflow:loss = 11.04, step = 501 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.078\n",
      "INFO:tensorflow:loss = 3.16476, step = 601 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.77\n",
      "INFO:tensorflow:loss = 0.685366, step = 701 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 566.917\n",
      "INFO:tensorflow:loss = 3.50312, step = 801 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.155\n",
      "INFO:tensorflow:loss = 35.5108, step = 901 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.986\n",
      "INFO:tensorflow:loss = 75.8451, step = 1001 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.904\n",
      "INFO:tensorflow:loss = 2.5661, step = 1101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.256\n",
      "INFO:tensorflow:loss = 1.56329, step = 1201 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.277\n",
      "INFO:tensorflow:loss = 0.641411, step = 1301 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.001\n",
      "INFO:tensorflow:loss = 1.86622, step = 1401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.731\n",
      "INFO:tensorflow:loss = 0.248482, step = 1501 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.105\n",
      "INFO:tensorflow:loss = 0.00540136, step = 1601 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.105\n",
      "INFO:tensorflow:loss = 9.6722, step = 1701 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.891\n",
      "INFO:tensorflow:loss = 5.61138, step = 1801 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.035\n",
      "INFO:tensorflow:loss = 5.78937, step = 1901 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.454\n",
      "INFO:tensorflow:loss = 2.03726, step = 2001 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.586\n",
      "INFO:tensorflow:loss = 0.0293412, step = 2101 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.546\n",
      "INFO:tensorflow:loss = 3.88654, step = 2201 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.953\n",
      "INFO:tensorflow:loss = 1.13815, step = 2301 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.695\n",
      "INFO:tensorflow:loss = 6.55795, step = 2401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.298\n",
      "INFO:tensorflow:loss = 0.997684, step = 2501 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.121\n",
      "INFO:tensorflow:loss = 0.625603, step = 2601 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.726\n",
      "INFO:tensorflow:loss = 11.8642, step = 2701 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.445\n",
      "INFO:tensorflow:loss = 1.34606, step = 2801 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.155\n",
      "INFO:tensorflow:loss = 6.49233, step = 2901 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.054\n",
      "INFO:tensorflow:loss = 2.39584, step = 3001 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.135\n",
      "INFO:tensorflow:loss = 1.14738, step = 3101 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.181\n",
      "INFO:tensorflow:loss = 0.0735651, step = 3201 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.569\n",
      "INFO:tensorflow:loss = 1.9803, step = 3301 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.532\n",
      "INFO:tensorflow:loss = 0.124432, step = 3401 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.004\n",
      "INFO:tensorflow:loss = 0.280568, step = 3501 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.631\n",
      "INFO:tensorflow:loss = 0.266392, step = 3601 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.535\n",
      "INFO:tensorflow:loss = 3.77453, step = 3701 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.074\n",
      "INFO:tensorflow:loss = 15.2194, step = 3801 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.731\n",
      "INFO:tensorflow:loss = 7.35636, step = 3901 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.314\n",
      "INFO:tensorflow:loss = 1.93617, step = 4001 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.844\n",
      "INFO:tensorflow:loss = 1.98659, step = 4101 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.359\n",
      "INFO:tensorflow:loss = 42.4538, step = 4201 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.637\n",
      "INFO:tensorflow:loss = 0.644975, step = 4301 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.637\n",
      "INFO:tensorflow:loss = 4.4139, step = 4401 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.684\n",
      "INFO:tensorflow:loss = 1.23795, step = 4501 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.771\n",
      "INFO:tensorflow:loss = 0.821454, step = 4601 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.531\n",
      "INFO:tensorflow:loss = 16.7794, step = 4701 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.033\n",
      "INFO:tensorflow:loss = 1.29146, step = 4801 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.878\n",
      "INFO:tensorflow:loss = 4.6501, step = 4901 (0.188 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into abalone_output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.30712.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-08-17:31:46\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-08-17:31:48\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 6.15007, rmse = 2.47993\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: abalone_output/export/Servo/1502213508/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine local train --package-path trainer \\\n",
    "   --module-name trainer.task \\\n",
    "   -- \\\n",
    "   --train-files gs://smiling-beaming-abalone/abalone_train.csv \\\n",
    "   --eval-files gs://smiling-beaming-abalone/abalone_test.csv \\\n",
    "   --job-dir abalone_output \\\n",
    "   --train-steps 5000 \\\n",
    "   --eval-steps 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code on CMLE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [abalone_170808_173148] submitted successfully.\n",
      "INFO\t2017-08-08 17:31:50 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2017-08-08 17:31:50 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2017-08-08 17:31:50 +0000\tservice\t\tJob abalone_170808_173148 is queued.\n",
      "INFO\t2017-08-08 17:31:51 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2017-08-08 17:31:51 +0000\tservice\t\tWaiting for TensorFlow to start.\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\tRunning task with arguments: --cluster={\"master\": [\"master-884bbd7962-0:2222\"], \"ps\": [\"ps-884bbd7962-0:2222\", \"ps-884bbd7962-1:2222\", \"ps-884bbd7962-2:2222\"], \"worker\": [\"worker-884bbd7962-0:2222\", \"worker-884bbd7962-1:2222\", \"worker-884bbd7962-2:2222\", \"worker-884bbd7962-3:2222\"]} --task={\"type\": \"worker\", \"index\": 3} --job={\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\t  \"package_uris\": [\"gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz\"],\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\t  \"python_module\": \"trainer.task\",\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\t  \"args\": [\"--train-files\", \"gs://smiling-beaming-abalone/abalone_train.csv\", \"--eval-files\", \"gs://smiling-beaming-abalone/abalone_test.csv\", \"--train-steps\", \"5000\", \"--eval-steps\", \"100\"],\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\t  \"region\": \"us-central1\",\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\t  \"runtime_version\": \"1.2\",\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\t  \"job_dir\": \"gs://smiling-beaming-abalone/abalone_170808_173148\"\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\t}\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\tRunning module trainer.task.\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\tDownloading the package: gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:33 +0000\tworker-replica-3\t\tRunning command: gsutil -q cp gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:34 +0000\tworker-replica-3\t\tInstalling the package: gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:34 +0000\tworker-replica-3\t\tRunning command: pip install --user --upgrade --force-reinstall --no-deps trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:35 +0000\tworker-replica-3\t\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:35 +0000\tworker-replica-3\t\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2017-08-08 17:37:35 +0000\tworker-replica-3\t\t  Running setup.py bdist_wheel for trainer: started\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tcreating '/tmp/tmpjDgDtLpip-wheel-/trainer-0.0.0-cp27-none-any.whl' and adding '.' to it\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tadding 'trainer/task.py'\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tadding 'trainer/__init__.py'\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/DESCRIPTION.rst'\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/metadata.json'\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/top_level.txt'\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/WHEEL'\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/METADATA'\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/RECORD'\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\t  Running setup.py bdist_wheel for trainer: finished with status 'done'\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tSuccessfully built trainer\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tInstalling collected packages: trainer\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tRunning command: pip install --user trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:36 +0000\tworker-replica-3\t\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\t  Requirement already satisfied (use --upgrade to upgrade): trainer==0.0.0 from file:///user_dir/trainer-0.0.0.tar.gz in /root/.local/lib/python2.7/site-packages\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\t  Running setup.py bdist_wheel for trainer: started\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tcreating '/tmp/tmp3EkBBIpip-wheel-/trainer-0.0.0-cp27-none-any.whl' and adding '.' to it\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tadding 'trainer/task.py'\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tadding 'trainer/__init__.py'\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/DESCRIPTION.rst'\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/metadata.json'\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/top_level.txt'\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/WHEEL'\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/METADATA'\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tadding 'trainer-0.0.0.dist-info/RECORD'\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\t  Running setup.py bdist_wheel for trainer: finished with status 'done'\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tSuccessfully built trainer\n",
      "INFO\t2017-08-08 17:37:37 +0000\tworker-replica-3\t\tRunning command: python -m trainer.task --train-files gs://smiling-beaming-abalone/abalone_train.csv --eval-files gs://smiling-beaming-abalone/abalone_test.csv --train-steps 5000 --eval-steps 100 --job-dir gs://smiling-beaming-abalone/abalone_170808_173148\n",
      "WARNING\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\tuid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\tUsing config: {'_model_dir': 'gs://smiling-beaming-abalone/abalone_170808_173148', '_save_checkpoints_secs': 600, '_num_ps_replicas': 3, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': u'worker', '_environment': u'cloud', '_is_chief': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc968dbec50>, '_tf_config': gpu_options {\n",
      "INFO\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\t  per_process_gpu_memory_fraction: 1.0\n",
      "INFO\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\t}\n",
      "INFO\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\t, '_num_worker_replicas': 4, '_task_id': 3, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': u'grpc://worker-884bbd7962-3:2222', '_session_config': None}\n",
      "WARNING\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\tuid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "ERROR\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\t2017-08-08 17:37:41.742626: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -> {0 -> master-884bbd7962-0:2222}\n",
      "ERROR\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\t2017-08-08 17:37:41.742687: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> ps-884bbd7962-0:2222, 1 -> ps-884bbd7962-1:2222, 2 -> ps-884bbd7962-2:2222}\n",
      "INFO\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\tWaiting 14 secs before starting training.\n",
      "ERROR\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\t2017-08-08 17:37:41.742698: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> worker-884bbd7962-0:2222, 1 -> worker-884bbd7962-1:2222, 2 -> worker-884bbd7962-2:2222, 3 -> localhost:2222}\n",
      "ERROR\t2017-08-08 17:37:41 +0000\tworker-replica-3\t\t2017-08-08 17:37:41.743106: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2222\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-0\t\t2017-08-08 17:37:42.336116: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:master/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-0\t\t2017-08-08 17:37:42.336267: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-0\t\t2017-08-08 17:37:42.336279: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-0\t\t2017-08-08 17:37:42.336285: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-0\t\t2017-08-08 17:37:42.336291: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-0\t\t2017-08-08 17:37:42.336301: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-1\t\t2017-08-08 17:37:42.467480: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:master/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-1\t\t2017-08-08 17:37:42.467588: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-1\t\t2017-08-08 17:37:42.467600: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-1\t\t2017-08-08 17:37:42.467607: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-1\t\t2017-08-08 17:37:42.467614: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:37:42 +0000\tworker-replica-1\t\t2017-08-08 17:37:42.467621: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "INFO\t2017-08-08 17:37:49 +0000\tworker-replica-2\t\tCreate CheckpointSaverHook.\n",
      "ERROR\t2017-08-08 17:37:52 +0000\tworker-replica-0\t\t2017-08-08 17:37:52.336419: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:master/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:37:52 +0000\tworker-replica-0\t\t2017-08-08 17:37:52.336501: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:37:52 +0000\tworker-replica-0\t\t2017-08-08 17:37:52.336526: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:37:52 +0000\tworker-replica-0\t\t2017-08-08 17:37:52.336533: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:37:52 +0000\tworker-replica-1\t\t2017-08-08 17:37:52.467791: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:master/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:37:52 +0000\tworker-replica-1\t\t2017-08-08 17:37:52.467876: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:37:52 +0000\tworker-replica-1\t\t2017-08-08 17:37:52.467887: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:37:52 +0000\tworker-replica-1\t\t2017-08-08 17:37:52.467895: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:37:52 +0000\tworker-replica-1\t\t2017-08-08 17:37:52.467901: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:2\n",
      "INFO\t2017-08-08 17:37:53 +0000\tps-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"master-884bbd7962-0:2222\"], \"ps\": [\"ps-884bbd7962-0:2222\", \"ps-884bbd7962-1:2222\", \"ps-884bbd7962-2:2222\"], \"worker\": [\"worker-884bbd7962-0:2222\", \"worker-884bbd7962-1:2222\", \"worker-884bbd7962-2:2222\", \"worker-884bbd7962-3:2222\"]} --task={\"type\": \"ps\", \"index\": 0} --job={\n",
      "INFO\t2017-08-08 17:37:53 +0000\tps-replica-0\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2017-08-08 17:37:53 +0000\tps-replica-0\t\t  \"package_uris\": [\"gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz\"],\n",
      "INFO\t2017-08-08 17:37:53 +0000\tps-replica-0\t\t  \"python_module\": \"trainer.task\",\n",
      "INFO\t2017-08-08 17:37:53 +0000\tps-replica-0\t\t  \"args\": [\"--train-files\", \"gs://smiling-beaming-abalone/abalone_train.csv\", \"--eval-files\", \"gs://smiling-beaming-abalone/abalone_test.csv\", \"--train-steps\", \"5000\", \"--eval-steps\", \"100\"],\n",
      "INFO\t2017-08-08 17:37:53 +0000\tps-replica-0\t\t  \"region\": \"us-central1\",\n",
      "INFO\t2017-08-08 17:37:53 +0000\tps-replica-0\t\t  \"runtime_version\": \"1.2\",\n",
      "INFO\t2017-08-08 17:37:53 +0000\tps-replica-0\t\t  \"job_dir\": \"gs://smiling-beaming-abalone/abalone_170808_173148\"\n",
      "INFO\t2017-08-08 17:37:53 +0000\tps-replica-0\t\t}\n",
      "INFO\t2017-08-08 17:37:54 +0000\tps-replica-0\t\tRunning module trainer.task.\n",
      "INFO\t2017-08-08 17:37:54 +0000\tps-replica-0\t\tDownloading the package: gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:54 +0000\tps-replica-0\t\tRunning command: gsutil -q cp gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:55 +0000\tps-replica-0\t\tInstalling the package: gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:55 +0000\tps-replica-0\t\tRunning command: pip install --user --upgrade --force-reinstall --no-deps trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:55 +0000\tps-replica-0\t\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\t  Running setup.py bdist_wheel for trainer: started\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\tRunning task with arguments: --cluster={\"master\": [\"master-884bbd7962-0:2222\"], \"ps\": [\"ps-884bbd7962-0:2222\", \"ps-884bbd7962-1:2222\", \"ps-884bbd7962-2:2222\"], \"worker\": [\"worker-884bbd7962-0:2222\", \"worker-884bbd7962-1:2222\", \"worker-884bbd7962-2:2222\", \"worker-884bbd7962-3:2222\"]} --task={\"type\": \"ps\", \"index\": 1} --job={\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\t  \"scale_tier\": \"STANDARD_1\",\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\t  \"package_uris\": [\"gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz\"],\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\t  \"python_module\": \"trainer.task\",\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\t  \"args\": [\"--train-files\", \"gs://smiling-beaming-abalone/abalone_train.csv\", \"--eval-files\", \"gs://smiling-beaming-abalone/abalone_test.csv\", \"--train-steps\", \"5000\", \"--eval-steps\", \"100\"],\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\t  \"region\": \"us-central1\",\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\t  \"runtime_version\": \"1.2\",\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\t  \"job_dir\": \"gs://smiling-beaming-abalone/abalone_170808_173148\"\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\t}\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tcreating '/tmp/tmpjMF71Tpip-wheel-/trainer-0.0.0-cp27-none-any.whl' and adding '.' to it\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tadding 'trainer/task.py'\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tadding 'trainer/__init__.py'\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/DESCRIPTION.rst'\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/metadata.json'\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/top_level.txt'\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/WHEEL'\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/METADATA'\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/RECORD'\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\t  Running setup.py bdist_wheel for trainer: finished with status 'done'\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tSuccessfully built trainer\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tInstalling collected packages: trainer\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tSuccessfully installed trainer-0.0.0\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-0\t\tRunning command: pip install --user trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\tRunning module trainer.task.\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\tDownloading the package: gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:56 +0000\tps-replica-1\t\tRunning command: gsutil -q cp gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:57 +0000\tworker-replica-3\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2017-08-08 17:37:57 +0000\tps-replica-0\t\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:57 +0000\tps-replica-0\t\t  Requirement already satisfied (use --upgrade to upgrade): trainer==0.0.0 from file:///user_dir/trainer-0.0.0.tar.gz in /root/.local/lib/python2.7/site-packages\n",
      "INFO\t2017-08-08 17:37:57 +0000\tps-replica-0\t\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2017-08-08 17:37:57 +0000\tps-replica-0\t\t  Running setup.py bdist_wheel for trainer: started\n",
      "INFO\t2017-08-08 17:37:57 +0000\tps-replica-1\t\tInstalling the package: gs://smiling-beaming-abalone/abalone_170808_173148/packages/e4e390faa84f90368f8bab0c1777c4b81c9daaddba6d08caf8601fce140101ee/trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:57 +0000\tps-replica-1\t\tRunning command: pip install --user --upgrade --force-reinstall --no-deps trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-1\t\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\tcreating '/tmp/tmpKSMbQupip-wheel-/trainer-0.0.0-cp27-none-any.whl' and adding '.' to it\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\tadding 'trainer/task.py'\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\tadding 'trainer/__init__.py'\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/DESCRIPTION.rst'\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/metadata.json'\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/top_level.txt'\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/WHEEL'\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/METADATA'\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\tadding 'trainer-0.0.0.dist-info/RECORD'\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\t  Running setup.py bdist_wheel for trainer: finished with status 'done'\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2017-08-08 17:37:58 +0000\tps-replica-0\t\tSuccessfully built trainer\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-0\t\tRunning command: python -m trainer.task --train-files gs://smiling-beaming-abalone/abalone_train.csv --eval-files gs://smiling-beaming-abalone/abalone_test.csv --train-steps 5000 --eval-steps 100 --job-dir gs://smiling-beaming-abalone/abalone_170808_173148\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\t  Running setup.py bdist_wheel for trainer: started\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tcreating '/tmp/tmpJCfajPpip-wheel-/trainer-0.0.0-cp27-none-any.whl' and adding '.' to it\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tadding 'trainer/task.py'\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tadding 'trainer/__init__.py'\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/DESCRIPTION.rst'\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/metadata.json'\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/top_level.txt'\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/WHEEL'\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/METADATA'\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/RECORD'\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\t  Running setup.py bdist_wheel for trainer: finished with status 'done'\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tSuccessfully built trainer\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tInstalling collected packages: trainer\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tSuccessfully installed trainer-0.0.0\n",
      "ERROR\t2017-08-08 17:37:59 +0000\tworker-replica-2\t\t2017-08-08 17:37:59.804006: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:master/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:37:59 +0000\tworker-replica-2\t\t2017-08-08 17:37:59.804102: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:37:59 +0000\tworker-replica-2\t\t2017-08-08 17:37:59.804114: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:37:59 +0000\tworker-replica-2\t\t2017-08-08 17:37:59.804120: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "INFO\t2017-08-08 17:37:59 +0000\tps-replica-1\t\tRunning command: pip install --user trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:38:00 +0000\tps-replica-1\t\tProcessing ./trainer-0.0.0.tar.gz\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\t  Requirement already satisfied (use --upgrade to upgrade): trainer==0.0.0 from file:///user_dir/trainer-0.0.0.tar.gz in /root/.local/lib/python2.7/site-packages\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\t  Running setup.py bdist_wheel for trainer: started\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tcreating '/tmp/tmp5C2uhUpip-wheel-/trainer-0.0.0-cp27-none-any.whl' and adding '.' to it\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tadding 'trainer/task.py'\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tadding 'trainer/__init__.py'\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/DESCRIPTION.rst'\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/metadata.json'\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/top_level.txt'\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/WHEEL'\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/METADATA'\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tadding 'trainer-0.0.0.dist-info/RECORD'\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\t  Running setup.py bdist_wheel for trainer: finished with status 'done'\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\t  Stored in directory: /root/.cache/pip/wheels/0d/1b/db/f8e86b296734f0b137e17e5d34862f4ae4faf8388755c6272f\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tSuccessfully built trainer\n",
      "INFO\t2017-08-08 17:38:01 +0000\tps-replica-1\t\tRunning command: python -m trainer.task --train-files gs://smiling-beaming-abalone/abalone_train.csv --eval-files gs://smiling-beaming-abalone/abalone_test.csv --train-steps 5000 --eval-steps 100 --job-dir gs://smiling-beaming-abalone/abalone_170808_173148\n",
      "ERROR\t2017-08-08 17:38:02 +0000\tworker-replica-0\t\t2017-08-08 17:38:02.336667: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:master/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:02 +0000\tworker-replica-0\t\t2017-08-08 17:38:02.336770: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:02 +0000\tworker-replica-0\t\t2017-08-08 17:38:02.336785: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:38:02 +0000\tworker-replica-0\t\t2017-08-08 17:38:02.336796: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:02 +0000\tworker-replica-1\t\t2017-08-08 17:38:02.468010: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:master/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:02 +0000\tworker-replica-1\t\t2017-08-08 17:38:02.468143: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:02 +0000\tworker-replica-1\t\t2017-08-08 17:38:02.468161: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:38:02 +0000\tworker-replica-1\t\t2017-08-08 17:38:02.468167: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "WARNING\t2017-08-08 17:38:03 +0000\tps-replica-0\t\tuid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO\t2017-08-08 17:38:04 +0000\tps-replica-0\t\tUsing config: {'_model_dir': 'gs://smiling-beaming-abalone/abalone_170808_173148', '_save_checkpoints_secs': 600, '_num_ps_replicas': 3, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': u'ps', '_environment': u'cloud', '_is_chief': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f06d8bfec50>, '_tf_config': gpu_options {\n",
      "INFO\t2017-08-08 17:38:04 +0000\tps-replica-0\t\t  per_process_gpu_memory_fraction: 1.0\n",
      "INFO\t2017-08-08 17:38:04 +0000\tps-replica-0\t\t}\n",
      "INFO\t2017-08-08 17:38:04 +0000\tps-replica-0\t\t, '_num_worker_replicas': 4, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': u'grpc://ps-884bbd7962-0:2222', '_session_config': None}\n",
      "WARNING\t2017-08-08 17:38:04 +0000\tps-replica-0\t\tuid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "ERROR\t2017-08-08 17:38:04 +0000\tps-replica-0\t\t2017-08-08 17:38:04.044949: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -> {0 -> master-884bbd7962-0:2222}\n",
      "ERROR\t2017-08-08 17:38:04 +0000\tps-replica-0\t\t2017-08-08 17:38:04.045256: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222, 1 -> ps-884bbd7962-1:2222, 2 -> ps-884bbd7962-2:2222}\n",
      "ERROR\t2017-08-08 17:38:04 +0000\tps-replica-0\t\t2017-08-08 17:38:04.045293: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> worker-884bbd7962-0:2222, 1 -> worker-884bbd7962-1:2222, 2 -> worker-884bbd7962-2:2222, 3 -> worker-884bbd7962-3:2222}\n",
      "ERROR\t2017-08-08 17:38:04 +0000\tps-replica-0\t\t2017-08-08 17:38:04.045766: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2222\n",
      "WARNING\t2017-08-08 17:38:06 +0000\tps-replica-1\t\tuid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO\t2017-08-08 17:38:06 +0000\tps-replica-1\t\tUsing config: {'_model_dir': 'gs://smiling-beaming-abalone/abalone_170808_173148', '_save_checkpoints_secs': 600, '_num_ps_replicas': 3, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': u'ps', '_environment': u'cloud', '_is_chief': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f520743ec50>, '_tf_config': gpu_options {\n",
      "INFO\t2017-08-08 17:38:06 +0000\tps-replica-1\t\t  per_process_gpu_memory_fraction: 1.0\n",
      "INFO\t2017-08-08 17:38:06 +0000\tps-replica-1\t\t}\n",
      "INFO\t2017-08-08 17:38:06 +0000\tps-replica-1\t\t, '_num_worker_replicas': 4, '_task_id': 1, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': u'grpc://ps-884bbd7962-1:2222', '_session_config': None}\n",
      "WARNING\t2017-08-08 17:38:06 +0000\tps-replica-1\t\tuid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "ERROR\t2017-08-08 17:38:06 +0000\tps-replica-1\t\t2017-08-08 17:38:06.682098: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -> {0 -> master-884bbd7962-0:2222}\n",
      "ERROR\t2017-08-08 17:38:06 +0000\tps-replica-1\t\t2017-08-08 17:38:06.682167: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> ps-884bbd7962-0:2222, 1 -> localhost:2222, 2 -> ps-884bbd7962-2:2222}\n",
      "ERROR\t2017-08-08 17:38:06 +0000\tps-replica-1\t\t2017-08-08 17:38:06.682190: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> worker-884bbd7962-0:2222, 1 -> worker-884bbd7962-1:2222, 2 -> worker-884bbd7962-2:2222, 3 -> worker-884bbd7962-3:2222}\n",
      "ERROR\t2017-08-08 17:38:06 +0000\tps-replica-1\t\t2017-08-08 17:38:06.683229: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:2222\n",
      "ERROR\t2017-08-08 17:38:07 +0000\tworker-replica-3\t\t2017-08-08 17:38:07.224119: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:07 +0000\tworker-replica-3\t\t2017-08-08 17:38:07.224236: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:38:07 +0000\tworker-replica-3\t\t2017-08-08 17:38:07.224254: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:09 +0000\tworker-replica-2\t\t2017-08-08 17:38:09.804280: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:09 +0000\tworker-replica-2\t\t2017-08-08 17:38:09.804357: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:38:09 +0000\tworker-replica-2\t\t2017-08-08 17:38:09.804365: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:12 +0000\tworker-replica-0\t\t2017-08-08 17:38:12.336934: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:master/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:12 +0000\tworker-replica-0\t\t2017-08-08 17:38:12.337024: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:12 +0000\tworker-replica-0\t\t2017-08-08 17:38:12.337034: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:38:12 +0000\tworker-replica-0\t\t2017-08-08 17:38:12.337040: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:12 +0000\tworker-replica-1\t\t2017-08-08 17:38:12.468315: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:12 +0000\tworker-replica-1\t\t2017-08-08 17:38:12.468415: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:38:12 +0000\tworker-replica-1\t\t2017-08-08 17:38:12.468431: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:17 +0000\tworker-replica-3\t\t2017-08-08 17:38:17.224403: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:17 +0000\tworker-replica-3\t\t2017-08-08 17:38:17.224537: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:38:17 +0000\tworker-replica-3\t\t2017-08-08 17:38:17.224548: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:19 +0000\tworker-replica-2\t\t2017-08-08 17:38:19.804528: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:20 +0000\tmaster-replica-0\t\t2017-08-08 17:38:20.758947: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:22 +0000\tworker-replica-0\t\t2017-08-08 17:38:22.337159: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0\n",
      "ERROR\t2017-08-08 17:38:22 +0000\tworker-replica-0\t\t2017-08-08 17:38:22.337244: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:38:22 +0000\tworker-replica-0\t\t2017-08-08 17:38:22.337256: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:22 +0000\tworker-replica-1\t\t2017-08-08 17:38:22.468574: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:38:22 +0000\tworker-replica-1\t\t2017-08-08 17:38:22.468686: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:27 +0000\tworker-replica-0\t\t2017-08-08 17:38:27.124669: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 4991dcd3442c3e84 with config: \n",
      "ERROR\t2017-08-08 17:38:27 +0000\tworker-replica-0\t\tgpu_options {\n",
      "ERROR\t2017-08-08 17:38:27 +0000\tworker-replica-0\t\t  per_process_gpu_memory_fraction: 1\n",
      "ERROR\t2017-08-08 17:38:27 +0000\tworker-replica-0\t\t}\n",
      "ERROR\t2017-08-08 17:38:27 +0000\tworker-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2017-08-08 17:38:27 +0000\tworker-replica-0\t\tWaiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: global_step, dense/kernel, dense/bias, dense_1/kernel, dense_1/bias, dense_2/kernel, dense_2/bias, OptimizeLoss/learning_rate, ready: None\n",
      "ERROR\t2017-08-08 17:38:27 +0000\tworker-replica-3\t\t2017-08-08 17:38:27.224693: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:28 +0000\tworker-replica-2\t\t2017-08-08 17:38:28.668734: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 34dbb6ffaf25ea96 with config: \n",
      "ERROR\t2017-08-08 17:38:28 +0000\tworker-replica-2\t\tgpu_options {\n",
      "ERROR\t2017-08-08 17:38:28 +0000\tworker-replica-2\t\t  per_process_gpu_memory_fraction: 1\n",
      "ERROR\t2017-08-08 17:38:28 +0000\tworker-replica-2\t\t}\n",
      "ERROR\t2017-08-08 17:38:28 +0000\tworker-replica-2\t\tallow_soft_placement: true\n",
      "INFO\t2017-08-08 17:38:28 +0000\tworker-replica-2\t\tWaiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: global_step, dense/kernel, dense/bias, dense_1/kernel, dense_1/bias, dense_2/kernel, dense_2/bias, OptimizeLoss/learning_rate, ready: None\n",
      "ERROR\t2017-08-08 17:38:29 +0000\tmaster-replica-0\t\t2017-08-08 17:38:29.565375: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 1ebf5f7fec6dd9db with config: \n",
      "ERROR\t2017-08-08 17:38:29 +0000\tmaster-replica-0\t\tgpu_options {\n",
      "ERROR\t2017-08-08 17:38:29 +0000\tmaster-replica-0\t\t  per_process_gpu_memory_fraction: 1\n",
      "ERROR\t2017-08-08 17:38:29 +0000\tmaster-replica-0\t\t}\n",
      "ERROR\t2017-08-08 17:38:29 +0000\tmaster-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2017-08-08 17:38:31 +0000\tmaster-replica-0\t\tSaving checkpoints for 0 into gs://smiling-beaming-abalone/abalone_170808_173148/model.ckpt.\n",
      "ERROR\t2017-08-08 17:38:32 +0000\tworker-replica-1\t\t2017-08-08 17:38:32.468843: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:38:32 +0000\tworker-replica-1\t\t2017-08-08 17:38:32.468944: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:ps/replica:0/task:2\n",
      "ERROR\t2017-08-08 17:38:34 +0000\tworker-replica-3\t\t2017-08-08 17:38:34.104517: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session d820575c8105bbc3 with config: \n",
      "ERROR\t2017-08-08 17:38:34 +0000\tworker-replica-3\t\tgpu_options {\n",
      "ERROR\t2017-08-08 17:38:34 +0000\tworker-replica-3\t\t  per_process_gpu_memory_fraction: 1\n",
      "ERROR\t2017-08-08 17:38:34 +0000\tworker-replica-3\t\t}\n",
      "ERROR\t2017-08-08 17:38:34 +0000\tworker-replica-3\t\tallow_soft_placement: true\n",
      "INFO\t2017-08-08 17:38:34 +0000\tworker-replica-3\t\tloss = 269.128, step = 1\n",
      "INFO\t2017-08-08 17:38:34 +0000\tworker-replica-3\t\tloss = 1.67545, step = 101 (0.406 sec)\n",
      "INFO\t2017-08-08 17:38:35 +0000\tworker-replica-3\t\tloss = 3.62848, step = 201 (0.454 sec)\n",
      "INFO\t2017-08-08 17:38:35 +0000\tworker-replica-3\t\tloss = 3.13283, step = 301 (0.429 sec)\n",
      "INFO\t2017-08-08 17:38:35 +0000\tworker-replica-3\t\tloss = 0.341095, step = 401 (0.422 sec)\n",
      "INFO\t2017-08-08 17:38:36 +0000\tworker-replica-3\t\tloss = 6.09551, step = 501 (0.436 sec)\n",
      "INFO\t2017-08-08 17:38:36 +0000\tworker-replica-3\t\tloss = 2.07723, step = 601 (0.435 sec)\n",
      "INFO\t2017-08-08 17:38:37 +0000\tworker-replica-3\t\tloss = 1.02225, step = 701 (0.413 sec)\n",
      "INFO\t2017-08-08 17:38:37 +0000\tworker-replica-3\t\tloss = 9.33577, step = 801 (0.416 sec)\n",
      "INFO\t2017-08-08 17:38:38 +0000\tworker-replica-3\t\tloss = 179.323, step = 901 (0.428 sec)\n",
      "INFO\t2017-08-08 17:38:38 +0000\tworker-replica-3\t\tloss = 0.405122, step = 1001 (0.396 sec)\n",
      "INFO\t2017-08-08 17:38:38 +0000\tworker-replica-3\t\tloss = 6.05955, step = 1101 (0.391 sec)\n",
      "INFO\t2017-08-08 17:38:39 +0000\tworker-replica-3\t\tloss = 0.191261, step = 1201 (0.384 sec)\n",
      "ERROR\t2017-08-08 17:38:39 +0000\tworker-replica-1\t\t2017-08-08 17:38:39.557898: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session bfed55306d6b4ce9 with config: \n",
      "ERROR\t2017-08-08 17:38:39 +0000\tworker-replica-1\t\tgpu_options {\n",
      "ERROR\t2017-08-08 17:38:39 +0000\tworker-replica-1\t\t  per_process_gpu_memory_fraction: 1\n",
      "ERROR\t2017-08-08 17:38:39 +0000\tworker-replica-1\t\t}\n",
      "ERROR\t2017-08-08 17:38:39 +0000\tworker-replica-1\t\tallow_soft_placement: true\n",
      "INFO\t2017-08-08 17:38:39 +0000\tworker-replica-3\t\tloss = 1.32161, step = 1301 (0.368 sec)\n",
      "INFO\t2017-08-08 17:38:39 +0000\tworker-replica-1\t\tloss = 21.8759, step = 1312\n",
      "INFO\t2017-08-08 17:38:40 +0000\tworker-replica-3\t\tloss = 1.52682, step = 1464 (0.404 sec)\n",
      "INFO\t2017-08-08 17:38:40 +0000\tworker-replica-1\t\tloss = 2.17567, step = 1539 (0.443 sec)\n",
      "INFO\t2017-08-08 17:38:40 +0000\tworker-replica-3\t\tloss = 60.6118, step = 1659 (0.412 sec)\n",
      "INFO\t2017-08-08 17:38:40 +0000\tworker-replica-1\t\tloss = 0.770538, step = 1749 (0.444 sec)\n",
      "INFO\t2017-08-08 17:38:40 +0000\tworker-replica-3\t\tloss = 10.5496, step = 1845 (0.389 sec)\n",
      "INFO\t2017-08-08 17:38:41 +0000\tworker-replica-1\t\tloss = 4.30292, step = 1966 (0.460 sec)\n",
      "INFO\t2017-08-08 17:38:41 +0000\tworker-replica-3\t\tloss = 7.00637, step = 2037 (0.412 sec)\n",
      "INFO\t2017-08-08 17:38:41 +0000\tworker-replica-1\t\tloss = 10.2806, step = 2164 (0.426 sec)\n",
      "INFO\t2017-08-08 17:38:41 +0000\tworker-replica-3\t\tloss = 0.010756, step = 2243 (0.440 sec)\n",
      "INFO\t2017-08-08 17:38:41 +0000\tworker-replica-1\t\tloss = 0.00926527, step = 2355 (0.408 sec)\n",
      "INFO\t2017-08-08 17:38:42 +0000\tworker-replica-3\t\tloss = 2.2878, step = 2451 (0.455 sec)\n",
      "INFO\t2017-08-08 17:38:42 +0000\tworker-replica-1\t\tloss = 7.40068, step = 2546 (0.413 sec)\n",
      "INFO\t2017-08-08 17:38:42 +0000\tmaster-replica-0\t\tloss = 42.5624, step = 0\n",
      "INFO\t2017-08-08 17:38:42 +0000\tworker-replica-3\t\tloss = 0.263891, step = 2663 (0.432 sec)\n",
      "INFO\t2017-08-08 17:38:42 +0000\tworker-replica-1\t\tloss = 0.00327025, step = 2735 (0.376 sec)\n",
      "INFO\t2017-08-08 17:38:43 +0000\tworker-replica-3\t\tloss = 1.1462, step = 2872 (0.418 sec)\n",
      "INFO\t2017-08-08 17:38:43 +0000\tworker-replica-1\t\tloss = 0.67508, step = 2927 (0.388 sec)\n",
      "INFO\t2017-08-08 17:38:43 +0000\tmaster-replica-0\t\tStarting evaluation at 2017-08-08-17:38:43\n",
      "INFO\t2017-08-08 17:38:43 +0000\tmaster-replica-0\t\tRestoring parameters from gs://smiling-beaming-abalone/abalone_170808_173148/model.ckpt-0\n",
      "INFO\t2017-08-08 17:38:43 +0000\tworker-replica-3\t\tloss = 1.36634, step = 3078 (0.421 sec)\n",
      "INFO\t2017-08-08 17:38:43 +0000\tworker-replica-1\t\tloss = 0.851613, step = 3121 (0.394 sec)\n",
      "INFO\t2017-08-08 17:38:43 +0000\tworker-replica-3\t\tloss = 2.82498, step = 3288 (0.435 sec)\n",
      "INFO\t2017-08-08 17:38:43 +0000\tworker-replica-1\t\tloss = 18.5275, step = 3313 (0.397 sec)\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [1/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [2/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [3/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [4/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [5/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [6/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [7/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [8/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [9/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [10/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [11/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [12/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [13/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tworker-replica-3\t\tloss = 16.2751, step = 3492 (0.404 sec)\n",
      "INFO\t2017-08-08 17:38:44 +0000\tworker-replica-1\t\tloss = 2.6387, step = 3511 (0.392 sec)\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [14/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [15/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [16/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [17/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [18/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [19/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [20/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [21/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [22/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [23/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [24/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [25/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [26/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [27/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [28/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [29/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [30/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [31/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [32/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [33/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [34/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [35/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [36/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [37/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [38/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [39/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [40/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [41/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [42/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [43/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [44/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [45/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [46/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [47/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [48/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [49/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [50/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [51/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [52/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [53/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tworker-replica-3\t\tloss = 56.8846, step = 3690 (0.381 sec)\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [54/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [55/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [56/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [57/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [58/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [59/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [60/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [61/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [62/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [63/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [64/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [65/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [66/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tworker-replica-1\t\tloss = 4.48157, step = 3712 (0.390 sec)\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [67/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [68/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [69/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [70/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [71/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [72/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [73/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [74/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [75/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [76/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [77/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [78/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [79/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [80/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [81/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [82/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [83/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [84/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [85/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [86/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [87/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [88/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [89/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [90/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [91/100]\n",
      "INFO\t2017-08-08 17:38:44 +0000\tmaster-replica-0\t\tEvaluation [92/100]\n",
      "INFO\t2017-08-08 17:38:45 +0000\tworker-replica-3\t\tloss = 22.5637, step = 3893 (0.404 sec)\n",
      "INFO\t2017-08-08 17:38:45 +0000\tworker-replica-1\t\tloss = 0.301212, step = 3909 (0.390 sec)\n",
      "INFO\t2017-08-08 17:38:45 +0000\tmaster-replica-0\t\tEvaluation [93/100]\n",
      "INFO\t2017-08-08 17:38:45 +0000\tmaster-replica-0\t\tEvaluation [94/100]\n",
      "INFO\t2017-08-08 17:38:45 +0000\tmaster-replica-0\t\tEvaluation [95/100]\n",
      "INFO\t2017-08-08 17:38:45 +0000\tmaster-replica-0\t\tEvaluation [96/100]\n",
      "INFO\t2017-08-08 17:38:45 +0000\tmaster-replica-0\t\tEvaluation [97/100]\n",
      "INFO\t2017-08-08 17:38:45 +0000\tmaster-replica-0\t\tEvaluation [98/100]\n",
      "INFO\t2017-08-08 17:38:45 +0000\tmaster-replica-0\t\tEvaluation [99/100]\n",
      "INFO\t2017-08-08 17:38:45 +0000\tmaster-replica-0\t\tEvaluation [100/100]\n",
      "INFO\t2017-08-08 17:38:45 +0000\tmaster-replica-0\t\tFinished evaluation at 2017-08-08-17:38:45\n",
      "INFO\t2017-08-08 17:38:45 +0000\tmaster-replica-0\t\tSaving dict for global step 1: global_step = 1, loss = 121.545, rmse = 11.0247\n",
      "INFO\t2017-08-08 17:38:45 +0000\tworker-replica-3\t\tloss = 1.17857, step = 4094 (0.398 sec)\n",
      "INFO\t2017-08-08 17:38:45 +0000\tworker-replica-1\t\tloss = 3.75373, step = 4109 (0.399 sec)\n",
      "INFO\t2017-08-08 17:38:45 +0000\tworker-replica-3\t\tloss = 5.66863, step = 4292 (0.367 sec)\n",
      "INFO\t2017-08-08 17:38:45 +0000\tworker-replica-1\t\tloss = 0.000200591, step = 4311 (0.366 sec)\n",
      "INFO\t2017-08-08 17:38:46 +0000\tworker-replica-3\t\tloss = 0.8216, step = 4491 (0.350 sec)\n",
      "INFO\t2017-08-08 17:38:46 +0000\tworker-replica-1\t\tloss = 1.18824, step = 4512 (0.360 sec)\n",
      "INFO\t2017-08-08 17:38:46 +0000\tworker-replica-3\t\tloss = 0.118404, step = 4687 (0.376 sec)\n",
      "INFO\t2017-08-08 17:38:46 +0000\tworker-replica-1\t\tloss = 12.3067, step = 4716 (0.392 sec)\n",
      "INFO\t2017-08-08 17:38:46 +0000\tworker-replica-3\t\tloss = 0.296982, step = 4889 (0.395 sec)\n",
      "INFO\t2017-08-08 17:38:46 +0000\tworker-replica-1\t\tloss = 26.6778, step = 4914 (0.386 sec)\n",
      "INFO\t2017-08-08 17:38:47 +0000\tworker-replica-1\t\tLoss for final step: 0.282605.\n",
      "INFO\t2017-08-08 17:38:47 +0000\tworker-replica-3\t\tLoss for final step: 64.6167.\n",
      "INFO\t2017-08-08 17:38:47 +0000\tworker-replica-3\t\tModule completed; cleaning up.\n",
      "INFO\t2017-08-08 17:38:47 +0000\tworker-replica-3\t\tClean up finished.\n",
      "INFO\t2017-08-08 17:38:47 +0000\tworker-replica-3\t\tTask completed successfully.\n",
      "INFO\t2017-08-08 17:38:47 +0000\tworker-replica-1\t\tModule completed; cleaning up.\n",
      "INFO\t2017-08-08 17:38:47 +0000\tworker-replica-1\t\tClean up finished.\n",
      "INFO\t2017-08-08 17:38:47 +0000\tworker-replica-1\t\tTask completed successfully.\n",
      "INFO\t2017-08-08 17:38:47 +0000\tmaster-replica-0\t\tValidation (step 1): loss = 121.545, global_step = 1, rmse = 11.0247\n",
      "INFO\t2017-08-08 17:38:47 +0000\tmaster-replica-0\t\tglobal_step/sec: 984.474\n",
      "INFO\t2017-08-08 17:38:47 +0000\tmaster-replica-0\t\tSaving checkpoints for 5003 into gs://smiling-beaming-abalone/abalone_170808_173148/model.ckpt.\n",
      "INFO\t2017-08-08 17:38:59 +0000\tmaster-replica-0\t\tLoss for final step: 18.7382.\n",
      "INFO\t2017-08-08 17:39:00 +0000\tmaster-replica-0\t\tStarting evaluation at 2017-08-08-17:39:00\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tRestoring parameters from gs://smiling-beaming-abalone/abalone_170808_173148/model.ckpt-5003\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [1/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [2/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [3/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [4/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [5/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [6/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [7/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [8/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [9/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [10/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [11/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [12/100]\n",
      "INFO\t2017-08-08 17:39:01 +0000\tmaster-replica-0\t\tEvaluation [13/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [14/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [15/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [16/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [17/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [18/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [19/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [20/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [21/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [22/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [23/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [24/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [25/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [26/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [27/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [28/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [29/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [30/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [31/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [32/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [33/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [34/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [35/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [36/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [37/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [38/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [39/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [40/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [41/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [42/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [43/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [44/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [45/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [46/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [47/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [48/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [49/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [50/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [51/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [52/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [53/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [54/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [55/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [56/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [57/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [58/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [59/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [60/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [61/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [62/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [63/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [64/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [65/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [66/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [67/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [68/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [69/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [70/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [71/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [72/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [73/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [74/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [75/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [76/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [77/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [78/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [79/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [80/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [81/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [82/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [83/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [84/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [85/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [86/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [87/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [88/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [89/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [90/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [91/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [92/100]\n",
      "INFO\t2017-08-08 17:39:02 +0000\tmaster-replica-0\t\tEvaluation [93/100]\n",
      "INFO\t2017-08-08 17:39:03 +0000\tmaster-replica-0\t\tEvaluation [94/100]\n",
      "INFO\t2017-08-08 17:39:03 +0000\tmaster-replica-0\t\tEvaluation [95/100]\n",
      "INFO\t2017-08-08 17:39:03 +0000\tmaster-replica-0\t\tEvaluation [96/100]\n",
      "INFO\t2017-08-08 17:39:03 +0000\tmaster-replica-0\t\tEvaluation [97/100]\n",
      "INFO\t2017-08-08 17:39:03 +0000\tmaster-replica-0\t\tEvaluation [98/100]\n",
      "INFO\t2017-08-08 17:39:03 +0000\tmaster-replica-0\t\tEvaluation [99/100]\n",
      "INFO\t2017-08-08 17:39:03 +0000\tmaster-replica-0\t\tEvaluation [100/100]\n",
      "INFO\t2017-08-08 17:39:03 +0000\tmaster-replica-0\t\tFinished evaluation at 2017-08-08-17:39:03\n",
      "INFO\t2017-08-08 17:39:03 +0000\tmaster-replica-0\t\tSaving dict for global step 5003: global_step = 5003, loss = 5.95721, rmse = 2.44074\n",
      "INFO\t2017-08-08 17:39:03 +0000\tmaster-replica-0\t\tRestoring parameters from gs://smiling-beaming-abalone/abalone_170808_173148/model.ckpt-5003\n",
      "INFO\t2017-08-08 17:39:06 +0000\tmaster-replica-0\t\tAssets added to graph.\n",
      "INFO\t2017-08-08 17:39:06 +0000\tmaster-replica-0\t\tNo assets to write.\n",
      "ERROR\t2017-08-08 17:39:07 +0000\tworker-replica-0\t\t2017-08-08 17:39:07.178954: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:39:07 +0000\tworker-replica-0\t\t2017-08-08 17:39:07.179045: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "ERROR\t2017-08-08 17:39:08 +0000\tworker-replica-2\t\t2017-08-08 17:39:08.737751: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:39:08 +0000\tworker-replica-2\t\t2017-08-08 17:39:08.737856: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "INFO\t2017-08-08 17:39:12 +0000\tmaster-replica-0\t\tSavedModel written to: gs://smiling-beaming-abalone/abalone_170808_173148/export/Servo/1502213943/saved_model.pb\n",
      "INFO\t2017-08-08 17:39:12 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2017-08-08 17:39:12 +0000\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2017-08-08 17:39:12 +0000\tmaster-replica-0\t\tTask completed successfully.\n",
      "ERROR\t2017-08-08 17:39:17 +0000\tworker-replica-0\t\t2017-08-08 17:39:17.179211: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:39:17 +0000\tworker-replica-0\t\t2017-08-08 17:39:17.179305: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "ERROR\t2017-08-08 17:39:18 +0000\tworker-replica-2\t\t2017-08-08 17:39:18.738008: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:39:18 +0000\tworker-replica-2\t\t2017-08-08 17:39:18.738097: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "INFO\t2017-08-08 17:39:23 +0000\tservice\t\tTearing down TensorFlow.\n",
      "INFO\t2017-08-08 17:39:23 +0000\tps-replica-0\t\tSignal 15 (SIGTERM) was caught. Terminated by service. This is normal behavior.\n",
      "INFO\t2017-08-08 17:39:23 +0000\tps-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2017-08-08 17:39:23 +0000\tps-replica-0\t\tClean up finished.\n",
      "INFO\t2017-08-08 17:39:23 +0000\tps-replica-1\t\tSignal 15 (SIGTERM) was caught. Terminated by service. This is normal behavior.\n",
      "INFO\t2017-08-08 17:39:23 +0000\tps-replica-1\t\tModule completed; cleaning up.\n",
      "INFO\t2017-08-08 17:39:23 +0000\tps-replica-1\t\tClean up finished.\n",
      "INFO\t2017-08-08 17:39:24 +0000\tps-replica-2\t\tSignal 15 (SIGTERM) was caught. Terminated by service. This is normal behavior.\n",
      "INFO\t2017-08-08 17:39:24 +0000\tps-replica-2\t\tModule completed; cleaning up.\n",
      "INFO\t2017-08-08 17:39:24 +0000\tps-replica-2\t\tClean up finished.\n",
      "INFO\t2017-08-08 17:39:24 +0000\tworker-replica-0\t\tSignal 15 (SIGTERM) was caught. Terminated by service. This is normal behavior.\n",
      "INFO\t2017-08-08 17:39:24 +0000\tworker-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2017-08-08 17:39:24 +0000\tworker-replica-0\t\tClean up finished.\n",
      "INFO\t2017-08-08 17:39:24 +0000\tworker-replica-2\t\tSignal 15 (SIGTERM) was caught. Terminated by service. This is normal behavior.\n",
      "INFO\t2017-08-08 17:39:24 +0000\tworker-replica-2\t\tModule completed; cleaning up.\n",
      "INFO\t2017-08-08 17:39:24 +0000\tworker-replica-2\t\tClean up finished.\n",
      "ERROR\t2017-08-08 17:39:27 +0000\tworker-replica-0\t\t2017-08-08 17:39:27.179472: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:39:27 +0000\tworker-replica-0\t\t2017-08-08 17:39:27.179599: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "ERROR\t2017-08-08 17:39:28 +0000\tworker-replica-2\t\t2017-08-08 17:39:28.738252: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:39:28 +0000\tworker-replica-2\t\t2017-08-08 17:39:28.738336: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "ERROR\t2017-08-08 17:39:37 +0000\tworker-replica-0\t\t2017-08-08 17:39:37.179725: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:39:37 +0000\tworker-replica-0\t\t2017-08-08 17:39:37.179824: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "ERROR\t2017-08-08 17:39:38 +0000\tworker-replica-2\t\t2017-08-08 17:39:38.738489: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:39:38 +0000\tworker-replica-2\t\t2017-08-08 17:39:38.738582: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "ERROR\t2017-08-08 17:39:47 +0000\tworker-replica-0\t\t2017-08-08 17:39:47.180020: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\n",
      "ERROR\t2017-08-08 17:39:47 +0000\tworker-replica-0\t\t2017-08-08 17:39:47.180109: I tensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\n",
      "INFO\t2017-08-08 17:40:53 +0000\tservice\t\tFinished tearing down TensorFlow.\n",
      "INFO\t2017-08-08 17:40:53 +0000\tservice\t\tJob completed successfully.\n",
      "endTime: '2017-08-08T17:39:23'\n",
      "jobId: abalone_170808_173148\n",
      "startTime: '2017-08-08T17:38:23'\n",
      "state: SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs submit training abalone_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --stream-logs \\\n",
    "  --scale-tier STANDARD_1 \\\n",
    "  --runtime-version 1.2 \\\n",
    "  --job-dir gs://smiling-beaming-abalone/abalone_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --module-name trainer.task \\\n",
    "  --package-path trainer \\\n",
    "  --region us-central1 \\\n",
    "  -- \\\n",
    "  --train-files gs://smiling-beaming-abalone/abalone_train.csv \\\n",
    "  --eval-files gs://smiling-beaming-abalone/abalone_test.csv \\\n",
    "  --train-steps 5000 \\\n",
    "  --eval-steps 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
