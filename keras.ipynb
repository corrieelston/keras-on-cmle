{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll change our model.  Originally it was defined using tf.contrib.layers, we'll change that to Keras.  Keras is being integrated as a first class citizen in TensorFlow and we'll use the version of Keras in tf.contrib.keras.  The integration is simple and profoundly beautiful, tf.contrib.learn, tf.contrib.layers and tf.contrib.keras are interoperable which makes using them, and mixing and matching them, extremely easy.\n",
    "\n",
    "Once you're happy with the changes made you can proceed to the [next notebook](keras-full.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_FILENAME = 'abalone_train.csv'\n",
    "TEST_FILENAME = 'abalone_test.csv'\n",
    "  \n",
    "training_dataset = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "    filename=TRAINING_FILENAME, target_dtype=np.int, features_dtype=np.float32)\n",
    "test_dataset = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "    filename=TEST_FILENAME, target_dtype=np.int, features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpdhHKin\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2025f1b2d0>, '_model_dir': '/tmp/tmpdhHKin', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpdhHKin/model.ckpt.\n",
      "INFO:tensorflow:loss = 106.959, step = 1\n",
      "INFO:tensorflow:global_step/sec: 641.503\n",
      "INFO:tensorflow:loss = 7.96988, step = 101 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.044\n",
      "INFO:tensorflow:loss = 7.53247, step = 201 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.744\n",
      "INFO:tensorflow:loss = 7.31645, step = 301 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.636\n",
      "INFO:tensorflow:loss = 7.1963, step = 401 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.545\n",
      "INFO:tensorflow:loss = 7.11967, step = 501 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.977\n",
      "INFO:tensorflow:loss = 7.06254, step = 601 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.077\n",
      "INFO:tensorflow:loss = 7.01351, step = 701 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.796\n",
      "INFO:tensorflow:loss = 6.9671, step = 801 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.067\n",
      "INFO:tensorflow:loss = 6.92267, step = 901 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.698\n",
      "INFO:tensorflow:loss = 6.87967, step = 1001 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.948\n",
      "INFO:tensorflow:loss = 6.83666, step = 1101 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.513\n",
      "INFO:tensorflow:loss = 6.79297, step = 1201 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.731\n",
      "INFO:tensorflow:loss = 6.74836, step = 1301 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.324\n",
      "INFO:tensorflow:loss = 6.70258, step = 1401 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.335\n",
      "INFO:tensorflow:loss = 6.6555, step = 1501 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.253\n",
      "INFO:tensorflow:loss = 6.60699, step = 1601 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.381\n",
      "INFO:tensorflow:loss = 6.55691, step = 1701 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.187\n",
      "INFO:tensorflow:loss = 6.50514, step = 1801 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.241\n",
      "INFO:tensorflow:loss = 6.45159, step = 1901 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.053\n",
      "INFO:tensorflow:loss = 6.39616, step = 2001 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.03\n",
      "INFO:tensorflow:loss = 6.33873, step = 2101 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.654\n",
      "INFO:tensorflow:loss = 6.27925, step = 2201 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.866\n",
      "INFO:tensorflow:loss = 6.21766, step = 2301 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.786\n",
      "INFO:tensorflow:loss = 6.15398, step = 2401 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.082\n",
      "INFO:tensorflow:loss = 6.08821, step = 2501 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 549.36\n",
      "INFO:tensorflow:loss = 6.02044, step = 2601 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.157\n",
      "INFO:tensorflow:loss = 5.9508, step = 2701 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.66\n",
      "INFO:tensorflow:loss = 5.87951, step = 2801 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.233\n",
      "INFO:tensorflow:loss = 5.80692, step = 2901 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.345\n",
      "INFO:tensorflow:loss = 5.73339, step = 3001 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.719\n",
      "INFO:tensorflow:loss = 5.65938, step = 3101 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.739\n",
      "INFO:tensorflow:loss = 5.58537, step = 3201 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.861\n",
      "INFO:tensorflow:loss = 5.51193, step = 3301 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.129\n",
      "INFO:tensorflow:loss = 5.43981, step = 3401 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.511\n",
      "INFO:tensorflow:loss = 5.36983, step = 3501 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.691\n",
      "INFO:tensorflow:loss = 5.30258, step = 3601 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.398\n",
      "INFO:tensorflow:loss = 5.23865, step = 3701 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.131\n",
      "INFO:tensorflow:loss = 5.17805, step = 3801 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.806\n",
      "INFO:tensorflow:loss = 5.12135, step = 3901 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.959\n",
      "INFO:tensorflow:loss = 5.06928, step = 4001 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.223\n",
      "INFO:tensorflow:loss = 5.02184, step = 4101 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.924\n",
      "INFO:tensorflow:loss = 4.97865, step = 4201 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.54\n",
      "INFO:tensorflow:loss = 4.93886, step = 4301 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.797\n",
      "INFO:tensorflow:loss = 4.90221, step = 4401 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.958\n",
      "INFO:tensorflow:loss = 4.86926, step = 4501 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.104\n",
      "INFO:tensorflow:loss = 4.84011, step = 4601 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.935\n",
      "INFO:tensorflow:loss = 4.81371, step = 4701 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.496\n",
      "INFO:tensorflow:loss = 4.78915, step = 4801 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.055\n",
      "INFO:tensorflow:loss = 4.76743, step = 4901 (0.152 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpdhHKin/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.74806.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-01-23:00:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpdhHKin/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-01-23:00:37\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.45964, rmse = 2.33659\n",
      "Loss: 5.45964\n",
      "Root Mean Squared Error: 2.33659\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Learning rate for the model\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "def model_fn(features, targets, mode, params):\n",
    "  \n",
    "  # Define our model in Keras\n",
    "  first_hidden_layer = Dense(10, activation='relu')(features)\n",
    "  second_hidden_layer = Dense(10, activation='relu')(first_hidden_layer)\n",
    "  output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "\n",
    "  # Reshape output layer to 1-dim Tensor to return predictions\n",
    "  predictions = tf.reshape(output_layer, [-1])\n",
    "  predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "  # Calculate loss using mean squared error\n",
    "  loss = tf.losses.mean_squared_error(targets, predictions)\n",
    "\n",
    "  # Calculate root mean squared error as additional eval metric\n",
    "  eval_metric_ops = {\n",
    "      \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "          tf.cast(targets, tf.float32), predictions)\n",
    "  }\n",
    "\n",
    "  train_op = tf.contrib.layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.contrib.framework.get_global_step(),\n",
    "      learning_rate=params[\"learning_rate\"],\n",
    "      optimizer=\"SGD\")\n",
    "\n",
    "  return model_fn_lib.ModelFnOps(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "# Set model params\n",
    "model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "# Instantiate Estimator\n",
    "nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)\n",
    "\n",
    "def get_train_inputs():\n",
    "  x = tf.constant(training_dataset.data)\n",
    "  y = tf.constant(training_dataset.target)\n",
    "  return x, y\n",
    "\n",
    "# Fit\n",
    "nn.fit(input_fn=get_train_inputs, steps=5000)\n",
    "\n",
    "# Score accuracy\n",
    "def get_test_inputs():\n",
    "  x = tf.constant(test_dataset.data)\n",
    "  y = tf.constant(test_dataset.target)\n",
    "  return x, y\n",
    "\n",
    "ev = nn.evaluate(input_fn=get_test_inputs, steps=1)\n",
    "print(\"Loss: %s\" % ev[\"loss\"])\n",
    "print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
