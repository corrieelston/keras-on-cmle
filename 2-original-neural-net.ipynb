{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the [original code](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/tutorials/estimators/abalone.py) from [this excellent tutorial](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/tutorials/estimators/abalone.py) and inlines it into a Datalab notebook.\n",
    "\n",
    "The model used is a 2 hidden layer, feed forward neural net.  Here's the definition.\n",
    "\n",
    "```\n",
    "first_hidden_layer = tf.contrib.layers.relu(features, 10)\n",
    "\n",
    "# Connect the second hidden layer to first hidden layer with relu\n",
    "second_hidden_layer = tf.contrib.layers.relu(first_hidden_layer, 10)\n",
    "\n",
    "# Connect the output layer to second hidden layer (no activation fn)\n",
    "output_layer = tf.contrib.layers.linear(second_hidden_layer, 1)\n",
    "```\n",
    "\n",
    "You should familiarize yourself with both the tutorial and code below and run this notebook in its entirety before proceeding to the [next notebook](3-tweaked-original-neural-net.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run this notebook you will see output from model training and evaluation such as the following.\n",
    "\n",
    "```\n",
    "INFO:tensorflow:loss = 4.63147, step = 4901 (0.192 sec)\n",
    "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp_Figkd/model.ckpt.\n",
    "INFO:tensorflow:Loss for final step: 4.62195.\n",
    "INFO:tensorflow:Starting evaluation at 2017-08-03-15:45:47\n",
    "INFO:tensorflow:Restoring parameters from /tmp/tmp_Figkd/model.ckpt-5000\n",
    "INFO:tensorflow:Evaluation [1/1]\n",
    "INFO:tensorflow:Finished evaluation at 2017-08-03-15:45:48\n",
    "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.38538, rmse = 2.32064\n",
    "Loss: 5.38538\n",
    "Root Mean Squared Error: 2.32064\n",
    "```\n",
    "\n",
    "Which shows the final few steps of the training of the model together with the final result of training.  The final result of training of interest to you is the [Root Mean Square Error (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation).  Essentially it is a measure of how bad our model is - how badly the model makes predictions on tesing data - and the smaller the number (the less bad :-)) the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is downloaded to /tmp/tmpJzEXcW\n",
      "Test data is downloaded to /tmp/tmpKQM_1J\n",
      "Prediction data is downloaded to /tmp/tmpZTk6xr\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp7vfv5R\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f42fa619bd0>, '_model_dir': '/tmp/tmp7vfv5R', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp7vfv5R/model.ckpt.\n",
      "INFO:tensorflow:loss = 101.688, step = 1\n",
      "INFO:tensorflow:global_step/sec: 449.834\n",
      "INFO:tensorflow:loss = 8.37939, step = 101 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.456\n",
      "INFO:tensorflow:loss = 7.92209, step = 201 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.1\n",
      "INFO:tensorflow:loss = 7.72135, step = 301 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.43\n",
      "INFO:tensorflow:loss = 7.61038, step = 401 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.05\n",
      "INFO:tensorflow:loss = 7.53413, step = 501 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.656\n",
      "INFO:tensorflow:loss = 7.47267, step = 601 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.974\n",
      "INFO:tensorflow:loss = 7.41807, step = 701 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.907\n",
      "INFO:tensorflow:loss = 7.36724, step = 801 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.502\n",
      "INFO:tensorflow:loss = 7.31903, step = 901 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.223\n",
      "INFO:tensorflow:loss = 7.27232, step = 1001 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.088\n",
      "INFO:tensorflow:loss = 7.22683, step = 1101 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.074\n",
      "INFO:tensorflow:loss = 7.18204, step = 1201 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.31\n",
      "INFO:tensorflow:loss = 7.13767, step = 1301 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.112\n",
      "INFO:tensorflow:loss = 7.09355, step = 1401 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.801\n",
      "INFO:tensorflow:loss = 7.04947, step = 1501 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.634\n",
      "INFO:tensorflow:loss = 7.00526, step = 1601 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.887\n",
      "INFO:tensorflow:loss = 6.96078, step = 1701 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.492\n",
      "INFO:tensorflow:loss = 6.91592, step = 1801 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.339\n",
      "INFO:tensorflow:loss = 6.87056, step = 1901 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.4\n",
      "INFO:tensorflow:loss = 6.82461, step = 2001 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.451\n",
      "INFO:tensorflow:loss = 6.778, step = 2101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.796\n",
      "INFO:tensorflow:loss = 6.7306, step = 2201 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.54\n",
      "INFO:tensorflow:loss = 6.68235, step = 2301 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.058\n",
      "INFO:tensorflow:loss = 6.63312, step = 2401 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.333\n",
      "INFO:tensorflow:loss = 6.58281, step = 2501 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.267\n",
      "INFO:tensorflow:loss = 6.53132, step = 2601 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.671\n",
      "INFO:tensorflow:loss = 6.47855, step = 2701 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.109\n",
      "INFO:tensorflow:loss = 6.4245, step = 2801 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.837\n",
      "INFO:tensorflow:loss = 6.36921, step = 2901 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.569\n",
      "INFO:tensorflow:loss = 6.31254, step = 3001 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.252\n",
      "INFO:tensorflow:loss = 6.25447, step = 3101 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.264\n",
      "INFO:tensorflow:loss = 6.19509, step = 3201 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.789\n",
      "INFO:tensorflow:loss = 6.13447, step = 3301 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.194\n",
      "INFO:tensorflow:loss = 6.07254, step = 3401 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.094\n",
      "INFO:tensorflow:loss = 6.00918, step = 3501 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.312\n",
      "INFO:tensorflow:loss = 5.94483, step = 3601 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.229\n",
      "INFO:tensorflow:loss = 5.87968, step = 3701 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.583\n",
      "INFO:tensorflow:loss = 5.81362, step = 3801 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.498\n",
      "INFO:tensorflow:loss = 5.74724, step = 3901 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.164\n",
      "INFO:tensorflow:loss = 5.68063, step = 4001 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.522\n",
      "INFO:tensorflow:loss = 5.61374, step = 4101 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.129\n",
      "INFO:tensorflow:loss = 5.54657, step = 4201 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.729\n",
      "INFO:tensorflow:loss = 5.48019, step = 4301 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.028\n",
      "INFO:tensorflow:loss = 5.41502, step = 4401 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.893\n",
      "INFO:tensorflow:loss = 5.35099, step = 4501 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.747\n",
      "INFO:tensorflow:loss = 5.28928, step = 4601 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.389\n",
      "INFO:tensorflow:loss = 5.23003, step = 4701 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.495\n",
      "INFO:tensorflow:loss = 5.17261, step = 4801 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.728\n",
      "INFO:tensorflow:loss = 5.11758, step = 4901 (0.200 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp7vfv5R/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.06693.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-07-20:54:43\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp7vfv5R/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-07-20:54:44\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.74951, rmse = 2.39781\n",
      "Loss: 5.74951\n",
      "Root Mean Squared Error: 2.39781\n",
      "WARNING:tensorflow:From <ipython-input-1-b1ded8480f2c>:157: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp7vfv5R/model.ckpt-5000\n",
      "Prediction 1: 4.85832158105\n",
      "Prediction 2: 10.1987035815\n",
      "Prediction 3: 7.08749617423\n",
      "Prediction 4: 10.594010221\n",
      "Prediction 5: 11.0934060936\n",
      "Prediction 6: 9.42875503347\n",
      "Prediction 7: 10.9989650188\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Learning rate for the model\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "def maybe_download(train_data, test_data, predict_data):\n",
    "  \"\"\"Maybe downloads training data and returns train and test file names.\"\"\"\n",
    "  if train_data:\n",
    "    train_file_name = train_data\n",
    "  else:\n",
    "    train_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_train.csv\",\n",
    "        train_file.name)\n",
    "    train_file_name = train_file.name\n",
    "    train_file.close()\n",
    "    print(\"Training data is downloaded to %s\" % train_file_name)\n",
    "\n",
    "  if test_data:\n",
    "    test_file_name = test_data\n",
    "  else:\n",
    "    test_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_test.csv\", test_file.name)\n",
    "    test_file_name = test_file.name\n",
    "    test_file.close()\n",
    "    print(\"Test data is downloaded to %s\" % test_file_name)\n",
    "\n",
    "  if predict_data:\n",
    "    predict_file_name = predict_data\n",
    "  else:\n",
    "    predict_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_predict.csv\",\n",
    "        predict_file.name)\n",
    "    predict_file_name = predict_file.name\n",
    "    predict_file.close()\n",
    "    print(\"Prediction data is downloaded to %s\" % predict_file_name)\n",
    "\n",
    "  return train_file_name, test_file_name, predict_file_name\n",
    "\n",
    "\n",
    "def model_fn(features, targets, mode, params):\n",
    "  \"\"\"Model function for Estimator.\"\"\"\n",
    "\n",
    "  # Connect the first hidden layer to input layer\n",
    "  # (features) with relu activation\n",
    "  first_hidden_layer = tf.contrib.layers.relu(features, 10)\n",
    "\n",
    "  # Connect the second hidden layer to first hidden layer with relu\n",
    "  second_hidden_layer = tf.contrib.layers.relu(first_hidden_layer, 10)\n",
    "\n",
    "  # Connect the output layer to second hidden layer (no activation fn)\n",
    "  output_layer = tf.contrib.layers.linear(second_hidden_layer, 1)\n",
    "\n",
    "  # Reshape output layer to 1-dim Tensor to return predictions\n",
    "  predictions = tf.reshape(output_layer, [-1])\n",
    "  predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "  # Calculate loss using mean squared error\n",
    "  loss = tf.losses.mean_squared_error(targets, predictions)\n",
    "\n",
    "  # Calculate root mean squared error as additional eval metric\n",
    "  eval_metric_ops = {\n",
    "      \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "          tf.cast(targets, tf.float64), predictions)\n",
    "  }\n",
    "\n",
    "  train_op = tf.contrib.layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.contrib.framework.get_global_step(),\n",
    "      learning_rate=params[\"learning_rate\"],\n",
    "      optimizer=\"SGD\")\n",
    "\n",
    "  return model_fn_lib.ModelFnOps(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  # Load datasets\n",
    "  abalone_train, abalone_test, abalone_predict = maybe_download(\n",
    "      FLAGS.train_data, FLAGS.test_data, FLAGS.predict_data)\n",
    "\n",
    "  # Training examples\n",
    "  training_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_train, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Test examples\n",
    "  test_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_test, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set of 7 examples for which to predict abalone ages\n",
    "  prediction_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_predict, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set model params\n",
    "  model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "  # Instantiate Estimator\n",
    "  nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)\n",
    "  \n",
    "  def get_train_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    return x, y\n",
    "  \n",
    "  # Fit\n",
    "  nn.fit(input_fn=get_train_inputs, steps=5000)\n",
    "\n",
    "  # Score accuracy\n",
    "  def get_test_inputs():\n",
    "    x = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "    return x, y\n",
    "  \n",
    "  ev = nn.evaluate(input_fn=get_test_inputs, steps=1)\n",
    "  print(\"Loss: %s\" % ev[\"loss\"])\n",
    "  print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])\n",
    "\n",
    "  # Print out predictions\n",
    "  predictions = nn.predict(x=prediction_set.data, as_iterable=True)\n",
    "  for i, p in enumerate(predictions):\n",
    "    print(\"Prediction %s: %s\" % (i + 1, p[\"ages\"]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "  parser.add_argument(\n",
    "      \"--train_data\", type=str, default=\"\", help=\"Path to the training data.\")\n",
    "  parser.add_argument(\n",
    "      \"--test_data\", type=str, default=\"\", help=\"Path to the test data.\")\n",
    "  parser.add_argument(\n",
    "      \"--predict_data\",\n",
    "      type=str,\n",
    "      default=\"\",\n",
    "      help=\"Path to the prediction data.\")\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
