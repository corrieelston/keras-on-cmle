{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is taken directly from [here](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/tutorials/estimators/abalone.py) which is the full code sample associated with [this tutorial](https://www.tensorflow.org/extend/estimators).  The tutorial itself is an excellent introduction to creating custom estimators using tf.contrib.learn.  I learned a lot from going through this code line by line and I encourage you to do the same before getting started on the remainder of the notebooks in this follow up solution.\n",
    "\n",
    "First question: Why a follow up solution?  Well, the original tutorial was extremely instructive but left me with a few unanswered questions afterwards:\n",
    "\n",
    "* How would I use this with Keras?\n",
    "* How would I run my Keras model on Google Cloud Machine Learning Engine (CMLE)?\n",
    "\n",
    "My rational was that Keras is widely used in industry for machine learning (ML) (some peple call it the lingua franca of deep learning), it's being integrated into the TensorFlow framework as a first class citizen, and more and more people are asking the question about how to integrate these technologies.\n",
    "\n",
    "So, in the interests of completeness, the original code is below and you should walk through this code and the original turorial before proceeding to the [next notebook](3-tweaked-original-neural-net.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is downloaded to /tmp/tmpz97uaR\n",
      "Test data is downloaded to /tmp/tmpA1AWAW\n",
      "Prediction data is downloaded to /tmp/tmpunlOYP\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpVNR26n\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdb4c2353d0>, '_model_dir': '/tmp/tmpVNR26n', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpVNR26n/model.ckpt.\n",
      "INFO:tensorflow:loss = 107.021, step = 1\n",
      "INFO:tensorflow:global_step/sec: 470.741\n",
      "INFO:tensorflow:loss = 7.82805, step = 101 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.964\n",
      "INFO:tensorflow:loss = 7.50443, step = 201 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.127\n",
      "INFO:tensorflow:loss = 7.34039, step = 301 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.711\n",
      "INFO:tensorflow:loss = 7.24248, step = 401 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.139\n",
      "INFO:tensorflow:loss = 7.17223, step = 501 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.432\n",
      "INFO:tensorflow:loss = 7.11718, step = 601 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.251\n",
      "INFO:tensorflow:loss = 7.06827, step = 701 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.285\n",
      "INFO:tensorflow:loss = 7.02239, step = 801 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.7\n",
      "INFO:tensorflow:loss = 6.97764, step = 901 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.253\n",
      "INFO:tensorflow:loss = 6.93313, step = 1001 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.404\n",
      "INFO:tensorflow:loss = 6.88843, step = 1101 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.949\n",
      "INFO:tensorflow:loss = 6.84331, step = 1201 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.831\n",
      "INFO:tensorflow:loss = 6.79756, step = 1301 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.121\n",
      "INFO:tensorflow:loss = 6.75104, step = 1401 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.36\n",
      "INFO:tensorflow:loss = 6.70361, step = 1501 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.403\n",
      "INFO:tensorflow:loss = 6.65511, step = 1601 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.285\n",
      "INFO:tensorflow:loss = 6.60543, step = 1701 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.488\n",
      "INFO:tensorflow:loss = 6.55444, step = 1801 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 539.707\n",
      "INFO:tensorflow:loss = 6.50202, step = 1901 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.527\n",
      "INFO:tensorflow:loss = 6.44807, step = 2001 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.625\n",
      "INFO:tensorflow:loss = 6.39248, step = 2101 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.036\n",
      "INFO:tensorflow:loss = 6.33515, step = 2201 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.713\n",
      "INFO:tensorflow:loss = 6.27605, step = 2301 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.004\n",
      "INFO:tensorflow:loss = 6.21512, step = 2401 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.838\n",
      "INFO:tensorflow:loss = 6.15237, step = 2501 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.04\n",
      "INFO:tensorflow:loss = 6.08783, step = 2601 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.861\n",
      "INFO:tensorflow:loss = 6.02158, step = 2701 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.574\n",
      "INFO:tensorflow:loss = 5.95376, step = 2801 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.971\n",
      "INFO:tensorflow:loss = 5.88455, step = 2901 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.836\n",
      "INFO:tensorflow:loss = 5.81413, step = 3001 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.971\n",
      "INFO:tensorflow:loss = 5.74271, step = 3101 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.122\n",
      "INFO:tensorflow:loss = 5.67061, step = 3201 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.153\n",
      "INFO:tensorflow:loss = 5.59828, step = 3301 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.095\n",
      "INFO:tensorflow:loss = 5.52642, step = 3401 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.309\n",
      "INFO:tensorflow:loss = 5.45689, step = 3501 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.453\n",
      "INFO:tensorflow:loss = 5.38975, step = 3601 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.761\n",
      "INFO:tensorflow:loss = 5.32597, step = 3701 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.985\n",
      "INFO:tensorflow:loss = 5.26569, step = 3801 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.362\n",
      "INFO:tensorflow:loss = 5.20913, step = 3901 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.035\n",
      "INFO:tensorflow:loss = 5.15701, step = 4001 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.709\n",
      "INFO:tensorflow:loss = 5.10933, step = 4101 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.295\n",
      "INFO:tensorflow:loss = 5.06579, step = 4201 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.716\n",
      "INFO:tensorflow:loss = 5.02673, step = 4301 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.11\n",
      "INFO:tensorflow:loss = 4.99227, step = 4401 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.854\n",
      "INFO:tensorflow:loss = 4.96204, step = 4501 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.621\n",
      "INFO:tensorflow:loss = 4.93569, step = 4601 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.925\n",
      "INFO:tensorflow:loss = 4.9124, step = 4701 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.683\n",
      "INFO:tensorflow:loss = 4.89136, step = 4801 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.222\n",
      "INFO:tensorflow:loss = 4.873, step = 4901 (0.199 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpVNR26n/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.85689.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-20:08:17\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpVNR26n/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-20:08:17\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.57301, rmse = 2.36072\n",
      "Loss: 5.57301\n",
      "Root Mean Squared Error: 2.36072\n",
      "WARNING:tensorflow:From <ipython-input-5-b1ded8480f2c>:157: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpVNR26n/model.ckpt-5000\n",
      "Prediction 1: 4.47292224246\n",
      "Prediction 2: 10.4847077545\n",
      "Prediction 3: 7.26490603041\n",
      "Prediction 4: 10.6776999855\n",
      "Prediction 5: 11.0588045148\n",
      "Prediction 6: 9.37217794986\n",
      "Prediction 7: 11.2721976609\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Learning rate for the model\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "def maybe_download(train_data, test_data, predict_data):\n",
    "  \"\"\"Maybe downloads training data and returns train and test file names.\"\"\"\n",
    "  if train_data:\n",
    "    train_file_name = train_data\n",
    "  else:\n",
    "    train_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_train.csv\",\n",
    "        train_file.name)\n",
    "    train_file_name = train_file.name\n",
    "    train_file.close()\n",
    "    print(\"Training data is downloaded to %s\" % train_file_name)\n",
    "\n",
    "  if test_data:\n",
    "    test_file_name = test_data\n",
    "  else:\n",
    "    test_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_test.csv\", test_file.name)\n",
    "    test_file_name = test_file.name\n",
    "    test_file.close()\n",
    "    print(\"Test data is downloaded to %s\" % test_file_name)\n",
    "\n",
    "  if predict_data:\n",
    "    predict_file_name = predict_data\n",
    "  else:\n",
    "    predict_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_predict.csv\",\n",
    "        predict_file.name)\n",
    "    predict_file_name = predict_file.name\n",
    "    predict_file.close()\n",
    "    print(\"Prediction data is downloaded to %s\" % predict_file_name)\n",
    "\n",
    "  return train_file_name, test_file_name, predict_file_name\n",
    "\n",
    "\n",
    "def model_fn(features, targets, mode, params):\n",
    "  \"\"\"Model function for Estimator.\"\"\"\n",
    "\n",
    "  # Connect the first hidden layer to input layer\n",
    "  # (features) with relu activation\n",
    "  first_hidden_layer = tf.contrib.layers.relu(features, 10)\n",
    "\n",
    "  # Connect the second hidden layer to first hidden layer with relu\n",
    "  second_hidden_layer = tf.contrib.layers.relu(first_hidden_layer, 10)\n",
    "\n",
    "  # Connect the output layer to second hidden layer (no activation fn)\n",
    "  output_layer = tf.contrib.layers.linear(second_hidden_layer, 1)\n",
    "\n",
    "  # Reshape output layer to 1-dim Tensor to return predictions\n",
    "  predictions = tf.reshape(output_layer, [-1])\n",
    "  predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "  # Calculate loss using mean squared error\n",
    "  loss = tf.losses.mean_squared_error(targets, predictions)\n",
    "\n",
    "  # Calculate root mean squared error as additional eval metric\n",
    "  eval_metric_ops = {\n",
    "      \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "          tf.cast(targets, tf.float64), predictions)\n",
    "  }\n",
    "\n",
    "  train_op = tf.contrib.layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.contrib.framework.get_global_step(),\n",
    "      learning_rate=params[\"learning_rate\"],\n",
    "      optimizer=\"SGD\")\n",
    "\n",
    "  return model_fn_lib.ModelFnOps(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  # Load datasets\n",
    "  abalone_train, abalone_test, abalone_predict = maybe_download(\n",
    "      FLAGS.train_data, FLAGS.test_data, FLAGS.predict_data)\n",
    "\n",
    "  # Training examples\n",
    "  training_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_train, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Test examples\n",
    "  test_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_test, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set of 7 examples for which to predict abalone ages\n",
    "  prediction_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_predict, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set model params\n",
    "  model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "  # Instantiate Estimator\n",
    "  nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)\n",
    "  \n",
    "  def get_train_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    return x, y\n",
    "  \n",
    "  # Fit\n",
    "  nn.fit(input_fn=get_train_inputs, steps=5000)\n",
    "\n",
    "  # Score accuracy\n",
    "  def get_test_inputs():\n",
    "    x = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "    return x, y\n",
    "  \n",
    "  ev = nn.evaluate(input_fn=get_test_inputs, steps=1)\n",
    "  print(\"Loss: %s\" % ev[\"loss\"])\n",
    "  print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])\n",
    "\n",
    "  # Print out predictions\n",
    "  predictions = nn.predict(x=prediction_set.data, as_iterable=True)\n",
    "  for i, p in enumerate(predictions):\n",
    "    print(\"Prediction %s: %s\" % (i + 1, p[\"ages\"]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "  parser.add_argument(\n",
    "      \"--train_data\", type=str, default=\"\", help=\"Path to the training data.\")\n",
    "  parser.add_argument(\n",
    "      \"--test_data\", type=str, default=\"\", help=\"Path to the test data.\")\n",
    "  parser.add_argument(\n",
    "      \"--predict_data\",\n",
    "      type=str,\n",
    "      default=\"\",\n",
    "      help=\"Path to the prediction data.\")\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
