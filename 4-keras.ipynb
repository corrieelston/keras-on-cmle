{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll change our model.  Originally it was defined using tf.contrib.layers, we'll change that to Keras.  Keras is being integrated as a first class citizen in TensorFlow and we'll use the version of Keras in tf.contrib.keras.  Originally the code looked like the following.\n",
    "\n",
    "```\n",
    "first_hidden_layer = tf.contrib.layers.relu(features, 10)\n",
    "\n",
    "# Connect the second hidden layer to first hidden layer with relu\n",
    "second_hidden_layer = tf.contrib.layers.relu(first_hidden_layer, 10)\n",
    "\n",
    "# Connect the output layer to second hidden layer (no activation fn)\n",
    "output_layer = tf.contrib.layers.linear(second_hidden_layer, 1)\n",
    "```\n",
    "\n",
    "The Keras version of the model looks like the following.\n",
    "\n",
    "```\n",
    "# Define our model in Keras\n",
    "first_hidden_layer = Dense(10, activation='relu')(features)\n",
    "second_hidden_layer = Dense(10, activation='relu')(first_hidden_layer)\n",
    "output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "```\n",
    "\n",
    "Both of these models are similarly concise because the aim of both is to provide an abstraction from raw TensorFlow.  The point of this solution is not to propose Keras as either superior or inferior to tf.contrib.learn or tf.contrib.layers.  The point is that it is enormously powerful and benefical to (a) be able to access Keras from the TensorFlow distribution and (b) to be able to mix and match tf.contrib.learn, tf.contrib.layers and Keras in the same model.\n",
    "\n",
    "You should familiarize yourself with the changes made, run this notebook in its entirety, then proceed to the [next notebook](5-keras-full.ipynb).\n",
    "\n",
    "The output from training and evaluation will be the same as before (N.B. because of the nature of neural net training the actual numbers will be similar but not exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_FILENAME = 'abalone_train.csv'\n",
    "TEST_FILENAME = 'abalone_test.csv'\n",
    "  \n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "    filename=TRAINING_FILENAME, target_dtype=np.int, features_dtype=np.float32)\n",
    "test_dataset = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "    filename=TEST_FILENAME, target_dtype=np.int, features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, targets, mode, params):\n",
    "  \n",
    "  # Define our model in Keras\n",
    "  first_hidden_layer = Dense(10, activation='relu')(features)\n",
    "  second_hidden_layer = Dense(10, activation='relu')(first_hidden_layer)\n",
    "  output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "\n",
    "  # Reshape output layer to 1-dim Tensor to return predictions\n",
    "  predictions = tf.reshape(output_layer, [-1])\n",
    "  predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "  # Calculate loss using mean squared error\n",
    "  loss = tf.losses.mean_squared_error(targets, predictions)\n",
    "\n",
    "  # Calculate root mean squared error as additional eval metric\n",
    "  eval_metric_ops = {\n",
    "      \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "          tf.cast(targets, tf.float32), predictions)\n",
    "  }\n",
    "\n",
    "  train_op = tf.contrib.layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.contrib.framework.get_global_step(),\n",
    "      learning_rate=params[\"learning_rate\"],\n",
    "      optimizer=\"SGD\")\n",
    "\n",
    "  return model_fn_lib.ModelFnOps(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzBe3c_\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff4b7a4bed0>, '_model_dir': '/tmp/tmpzBe3c_', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpzBe3c_/model.ckpt.\n",
      "INFO:tensorflow:loss = 140.183, step = 1\n",
      "INFO:tensorflow:global_step/sec: 610.27\n",
      "INFO:tensorflow:loss = 8.59873, step = 101 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.638\n",
      "INFO:tensorflow:loss = 7.41668, step = 201 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.915\n",
      "INFO:tensorflow:loss = 7.21045, step = 301 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.834\n",
      "INFO:tensorflow:loss = 7.09823, step = 401 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.58\n",
      "INFO:tensorflow:loss = 7.02284, step = 501 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.901\n",
      "INFO:tensorflow:loss = 6.96731, step = 601 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.945\n",
      "INFO:tensorflow:loss = 6.92173, step = 701 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.975\n",
      "INFO:tensorflow:loss = 6.88095, step = 801 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.497\n",
      "INFO:tensorflow:loss = 6.84259, step = 901 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.117\n",
      "INFO:tensorflow:loss = 6.80519, step = 1001 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.541\n",
      "INFO:tensorflow:loss = 6.76794, step = 1101 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.015\n",
      "INFO:tensorflow:loss = 6.73036, step = 1201 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.455\n",
      "INFO:tensorflow:loss = 6.69212, step = 1301 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.311\n",
      "INFO:tensorflow:loss = 6.65299, step = 1401 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.694\n",
      "INFO:tensorflow:loss = 6.6128, step = 1501 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.688\n",
      "INFO:tensorflow:loss = 6.57139, step = 1601 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.74\n",
      "INFO:tensorflow:loss = 6.52856, step = 1701 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.319\n",
      "INFO:tensorflow:loss = 6.48421, step = 1801 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 576.691\n",
      "INFO:tensorflow:loss = 6.4382, step = 1901 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.387\n",
      "INFO:tensorflow:loss = 6.39036, step = 2001 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 599.704\n",
      "INFO:tensorflow:loss = 6.34055, step = 2101 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.191\n",
      "INFO:tensorflow:loss = 6.28862, step = 2201 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.448\n",
      "INFO:tensorflow:loss = 6.23453, step = 2301 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.77\n",
      "INFO:tensorflow:loss = 6.17815, step = 2401 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.697\n",
      "INFO:tensorflow:loss = 6.11943, step = 2501 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 566.274\n",
      "INFO:tensorflow:loss = 6.05835, step = 2601 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.485\n",
      "INFO:tensorflow:loss = 5.99493, step = 2701 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.472\n",
      "INFO:tensorflow:loss = 5.92928, step = 2801 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.755\n",
      "INFO:tensorflow:loss = 5.86151, step = 2901 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.475\n",
      "INFO:tensorflow:loss = 5.79188, step = 3001 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.479\n",
      "INFO:tensorflow:loss = 5.72077, step = 3101 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.47\n",
      "INFO:tensorflow:loss = 5.64855, step = 3201 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.606\n",
      "INFO:tensorflow:loss = 5.57586, step = 3301 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.223\n",
      "INFO:tensorflow:loss = 5.50325, step = 3401 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.809\n",
      "INFO:tensorflow:loss = 5.43115, step = 3501 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.629\n",
      "INFO:tensorflow:loss = 5.36023, step = 3601 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.149\n",
      "INFO:tensorflow:loss = 5.29127, step = 3701 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.84\n",
      "INFO:tensorflow:loss = 5.22479, step = 3801 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.518\n",
      "INFO:tensorflow:loss = 5.16133, step = 3901 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.255\n",
      "INFO:tensorflow:loss = 5.10058, step = 4001 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.664\n",
      "INFO:tensorflow:loss = 5.04383, step = 4101 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.4\n",
      "INFO:tensorflow:loss = 4.98989, step = 4201 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.45\n",
      "INFO:tensorflow:loss = 4.94003, step = 4301 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.227\n",
      "INFO:tensorflow:loss = 4.89234, step = 4401 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 588.484\n",
      "INFO:tensorflow:loss = 4.8492, step = 4501 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 624.882\n",
      "INFO:tensorflow:loss = 4.80905, step = 4601 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.891\n",
      "INFO:tensorflow:loss = 4.77189, step = 4701 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.222\n",
      "INFO:tensorflow:loss = 4.73858, step = 4801 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.741\n",
      "INFO:tensorflow:loss = 4.7087, step = 4901 (0.160 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpzBe3c_/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.68252.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-07-20:55:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzBe3c_/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-07-20:55:37\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.4036, rmse = 2.32457\n",
      "Loss: 5.4036\n",
      "Root Mean Squared Error: 2.32457\n"
     ]
    }
   ],
   "source": [
    "# Set model params\n",
    "model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "# Instantiate Estimator\n",
    "nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)\n",
    "\n",
    "def get_train_inputs():\n",
    "  x = tf.constant(training_dataset.data)\n",
    "  y = tf.constant(training_dataset.target)\n",
    "  return x, y\n",
    "\n",
    "# Fit\n",
    "nn.fit(input_fn=get_train_inputs, steps=5000)\n",
    "\n",
    "# Score accuracy\n",
    "def get_test_inputs():\n",
    "  x = tf.constant(test_dataset.data)\n",
    "  y = tf.constant(test_dataset.target)\n",
    "  return x, y\n",
    "\n",
    "ev = nn.evaluate(input_fn=get_test_inputs, steps=1)\n",
    "print(\"Loss: %s\" % ev[\"loss\"])\n",
    "print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
