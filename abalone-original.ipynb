{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is downloaded to /tmp/tmpW070b7\n",
      "Test data is downloaded to /tmp/tmplwSZEl\n",
      "Prediction data is downloaded to /tmp/tmp4mxjDh\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmplaN3Q_\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdb54754910>, '_model_dir': '/tmp/tmplaN3Q_', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmplaN3Q_/model.ckpt.\n",
      "INFO:tensorflow:loss = 110.671, step = 1\n",
      "INFO:tensorflow:global_step/sec: 533.257\n",
      "INFO:tensorflow:loss = 7.31927, step = 101 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.071\n",
      "INFO:tensorflow:loss = 7.09756, step = 201 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 558.164\n",
      "INFO:tensorflow:loss = 6.98201, step = 301 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 549.677\n",
      "INFO:tensorflow:loss = 6.90636, step = 401 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 551.518\n",
      "INFO:tensorflow:loss = 6.84442, step = 501 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.67\n",
      "INFO:tensorflow:loss = 6.77443, step = 601 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.723\n",
      "INFO:tensorflow:loss = 6.71337, step = 701 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.577\n",
      "INFO:tensorflow:loss = 6.66298, step = 801 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.662\n",
      "INFO:tensorflow:loss = 6.6164, step = 901 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.412\n",
      "INFO:tensorflow:loss = 6.56932, step = 1001 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 559.006\n",
      "INFO:tensorflow:loss = 6.5208, step = 1101 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.578\n",
      "INFO:tensorflow:loss = 6.4713, step = 1201 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.569\n",
      "INFO:tensorflow:loss = 6.42057, step = 1301 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.774\n",
      "INFO:tensorflow:loss = 6.36809, step = 1401 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.961\n",
      "INFO:tensorflow:loss = 6.31403, step = 1501 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.387\n",
      "INFO:tensorflow:loss = 6.25818, step = 1601 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 551.91\n",
      "INFO:tensorflow:loss = 6.20056, step = 1701 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.862\n",
      "INFO:tensorflow:loss = 6.14132, step = 1801 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 542.664\n",
      "INFO:tensorflow:loss = 6.08019, step = 1901 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.505\n",
      "INFO:tensorflow:loss = 6.01734, step = 2001 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.598\n",
      "INFO:tensorflow:loss = 5.952, step = 2101 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 550.503\n",
      "INFO:tensorflow:loss = 5.88504, step = 2201 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.288\n",
      "INFO:tensorflow:loss = 5.81673, step = 2301 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 541.36\n",
      "INFO:tensorflow:loss = 5.74782, step = 2401 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.406\n",
      "INFO:tensorflow:loss = 5.67833, step = 2501 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.129\n",
      "INFO:tensorflow:loss = 5.60652, step = 2601 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.585\n",
      "INFO:tensorflow:loss = 5.49753, step = 2701 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.17\n",
      "INFO:tensorflow:loss = 5.42792, step = 2801 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.173\n",
      "INFO:tensorflow:loss = 5.3631, step = 2901 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.281\n",
      "INFO:tensorflow:loss = 5.30171, step = 3001 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.654\n",
      "INFO:tensorflow:loss = 5.24403, step = 3101 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.024\n",
      "INFO:tensorflow:loss = 5.19012, step = 3201 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.823\n",
      "INFO:tensorflow:loss = 5.14034, step = 3301 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.656\n",
      "INFO:tensorflow:loss = 5.09483, step = 3401 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.657\n",
      "INFO:tensorflow:loss = 5.05365, step = 3501 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.201\n",
      "INFO:tensorflow:loss = 5.0167, step = 3601 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.452\n",
      "INFO:tensorflow:loss = 4.98398, step = 3701 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.851\n",
      "INFO:tensorflow:loss = 4.95513, step = 3801 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.694\n",
      "INFO:tensorflow:loss = 4.92987, step = 3901 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.155\n",
      "INFO:tensorflow:loss = 4.90781, step = 4001 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.828\n",
      "INFO:tensorflow:loss = 4.88836, step = 4101 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.571\n",
      "INFO:tensorflow:loss = 4.87153, step = 4201 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.431\n",
      "INFO:tensorflow:loss = 4.85692, step = 4301 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.446\n",
      "INFO:tensorflow:loss = 4.84428, step = 4401 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.102\n",
      "INFO:tensorflow:loss = 4.83292, step = 4501 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.581\n",
      "INFO:tensorflow:loss = 4.82247, step = 4601 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.442\n",
      "INFO:tensorflow:loss = 4.81315, step = 4701 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.008\n",
      "INFO:tensorflow:loss = 4.80511, step = 4801 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.83\n",
      "INFO:tensorflow:loss = 4.79851, step = 4901 (0.194 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmplaN3Q_/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.79297.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-19-21:19:05\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmplaN3Q_/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-19-21:19:05\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 5.53269, rmse = 2.35217\n",
      "Loss: 5.53269\n",
      "Root Mean Squared Error: 2.35217\n",
      "WARNING:tensorflow:From <ipython-input-1-b1ded8480f2c>:157: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmplaN3Q_/model.ckpt-5000\n",
      "Prediction 1: 4.58884780619\n",
      "Prediction 2: 10.5525403575\n",
      "Prediction 3: 7.18585047608\n",
      "Prediction 4: 10.8856580532\n",
      "Prediction 5: 10.9568594328\n",
      "Prediction 6: 9.42200872521\n",
      "Prediction 7: 11.3994775635\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"DNNRegressor with custom estimator for abalone dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Learning rate for the model\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "def maybe_download(train_data, test_data, predict_data):\n",
    "  \"\"\"Maybe downloads training data and returns train and test file names.\"\"\"\n",
    "  if train_data:\n",
    "    train_file_name = train_data\n",
    "  else:\n",
    "    train_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_train.csv\",\n",
    "        train_file.name)\n",
    "    train_file_name = train_file.name\n",
    "    train_file.close()\n",
    "    print(\"Training data is downloaded to %s\" % train_file_name)\n",
    "\n",
    "  if test_data:\n",
    "    test_file_name = test_data\n",
    "  else:\n",
    "    test_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_test.csv\", test_file.name)\n",
    "    test_file_name = test_file.name\n",
    "    test_file.close()\n",
    "    print(\"Test data is downloaded to %s\" % test_file_name)\n",
    "\n",
    "  if predict_data:\n",
    "    predict_file_name = predict_data\n",
    "  else:\n",
    "    predict_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    urllib.request.urlretrieve(\n",
    "        \"http://download.tensorflow.org/data/abalone_predict.csv\",\n",
    "        predict_file.name)\n",
    "    predict_file_name = predict_file.name\n",
    "    predict_file.close()\n",
    "    print(\"Prediction data is downloaded to %s\" % predict_file_name)\n",
    "\n",
    "  return train_file_name, test_file_name, predict_file_name\n",
    "\n",
    "\n",
    "def model_fn(features, targets, mode, params):\n",
    "  \"\"\"Model function for Estimator.\"\"\"\n",
    "\n",
    "  # Connect the first hidden layer to input layer\n",
    "  # (features) with relu activation\n",
    "  first_hidden_layer = tf.contrib.layers.relu(features, 10)\n",
    "\n",
    "  # Connect the second hidden layer to first hidden layer with relu\n",
    "  second_hidden_layer = tf.contrib.layers.relu(first_hidden_layer, 10)\n",
    "\n",
    "  # Connect the output layer to second hidden layer (no activation fn)\n",
    "  output_layer = tf.contrib.layers.linear(second_hidden_layer, 1)\n",
    "\n",
    "  # Reshape output layer to 1-dim Tensor to return predictions\n",
    "  predictions = tf.reshape(output_layer, [-1])\n",
    "  predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "  # Calculate loss using mean squared error\n",
    "  loss = tf.losses.mean_squared_error(targets, predictions)\n",
    "\n",
    "  # Calculate root mean squared error as additional eval metric\n",
    "  eval_metric_ops = {\n",
    "      \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "          tf.cast(targets, tf.float64), predictions)\n",
    "  }\n",
    "\n",
    "  train_op = tf.contrib.layers.optimize_loss(\n",
    "      loss=loss,\n",
    "      global_step=tf.contrib.framework.get_global_step(),\n",
    "      learning_rate=params[\"learning_rate\"],\n",
    "      optimizer=\"SGD\")\n",
    "\n",
    "  return model_fn_lib.ModelFnOps(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  # Load datasets\n",
    "  abalone_train, abalone_test, abalone_predict = maybe_download(\n",
    "      FLAGS.train_data, FLAGS.test_data, FLAGS.predict_data)\n",
    "\n",
    "  # Training examples\n",
    "  training_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_train, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Test examples\n",
    "  test_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_test, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set of 7 examples for which to predict abalone ages\n",
    "  prediction_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_predict, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set model params\n",
    "  model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "  # Instantiate Estimator\n",
    "  nn = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)\n",
    "  \n",
    "  def get_train_inputs():\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    return x, y\n",
    "  \n",
    "  # Fit\n",
    "  nn.fit(input_fn=get_train_inputs, steps=5000)\n",
    "\n",
    "  # Score accuracy\n",
    "  def get_test_inputs():\n",
    "    x = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "    return x, y\n",
    "  \n",
    "  ev = nn.evaluate(input_fn=get_test_inputs, steps=1)\n",
    "  print(\"Loss: %s\" % ev[\"loss\"])\n",
    "  print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])\n",
    "\n",
    "  # Print out predictions\n",
    "  predictions = nn.predict(x=prediction_set.data, as_iterable=True)\n",
    "  for i, p in enumerate(predictions):\n",
    "    print(\"Prediction %s: %s\" % (i + 1, p[\"ages\"]))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "  parser.add_argument(\n",
    "      \"--train_data\", type=str, default=\"\", help=\"Path to the training data.\")\n",
    "  parser.add_argument(\n",
    "      \"--test_data\", type=str, default=\"\", help=\"Path to the test data.\")\n",
    "  parser.add_argument(\n",
    "      \"--predict_data\",\n",
    "      type=str,\n",
    "      default=\"\",\n",
    "      help=\"Path to the prediction data.\")\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
