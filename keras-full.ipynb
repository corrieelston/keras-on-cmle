{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Keras Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a version of our model that integrates Keras into the customer estimator from tf.contrib.learn we can proceed to add in additional code required to train this model on Google Cloud Machine Learning Engine (CMLE).  There are a relatively small number of changes required to get a big uplift in functionality together with the ability to run locally or deploy to CMLE with equal ease from the command line.  Changes will be explained as the solution progresses.\n",
    "\n",
    "At a high level we do two things:\n",
    "\n",
    "* Change the mechanism for accessing training/test data from reading directly from local files to reading files from Google Cloud Storage (GCS).\n",
    "* Encapsulate the model and additional requirements into an Experiment which in turn managed by a learn_runner from tf.contrib.learn.  Experiment has the functionality required to train and evaluate a model in a distributed environment, including checkpointing progress, reporting summaries that can be consumed by TensorBoard, etc.  In turn learn_runner is a utility that helps run and tune an Experiment.\n",
    "\n",
    "One change from usual practice called out in advance is that usually TensorFlow modelling, especially for CMLE, the model is placed in one file and the associated code to run it is placed in another.  These are usually called model and task.  This is a sensible separation of concerns because it makes it easier to swap models easily.  However, for the purposes of this tutorial I'm combining both into a single notebook/file for convenience.\n",
    "\n",
    "When you're happy with this proceed to the [next notebook](distributed-keras-local.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell deletes a local directory used when this model is trained locally (i.e. by running this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf abalone_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import six\n",
    "from six.moves import urllib\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section follows standard TensorFlow practices for production grade machine learning.  It defines how to decode a line from a CSV file (together with sensible defaults), instantiates a queue of filenames (in this case we have one), then connects the content of the CSV file to a batching mechanism (that either shuffles the data - usual practice in the case of training - or not - usual practice in the case of evaluation) that encapsulates the details of reading the data, buffering data for training, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['length', 'diameter', 'height', 'whole_weight', 'shucked_weight',\n",
    "               'viscera_weight', 'shell_weight', 'num_rings']\n",
    "CSV_COLUMN_DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0]]\n",
    "\n",
    "PREDICTED_COLUMN = 'num_rings'\n",
    "INPUT_COLUMNS = [\n",
    "    tf.feature_column.numeric_column('length'),\n",
    "    tf.feature_column.numeric_column('diameter'),\n",
    "    tf.feature_column.numeric_column('height'),\n",
    "    tf.feature_column.numeric_column('whole_weight'),\n",
    "    tf.feature_column.numeric_column('shucked_weight'),\n",
    "    tf.feature_column.numeric_column('viscera_weight'),\n",
    "    tf.feature_column.numeric_column('shell_weight'),\n",
    "]\n",
    "\n",
    "UNUSED_COLUMNS = set(CSV_COLUMNS) - {col.name for col in INPUT_COLUMNS} - {PREDICTED_COLUMN}\n",
    "\n",
    "def parse_csv(rows_string_tensor):\n",
    "  columns = tf.decode_csv(rows_string_tensor, record_defaults=CSV_COLUMN_DEFAULTS)\n",
    "  features = dict(zip(CSV_COLUMNS, columns))\n",
    "\n",
    "  for col in UNUSED_COLUMNS:\n",
    "    features.pop(col)\n",
    "\n",
    "  for key, value in six.iteritems(features):\n",
    "    features[key] = tf.expand_dims(features[key], -1)\n",
    "  return features\n",
    "\n",
    "def generate_input_fn(filenames,\n",
    "                      num_epochs=None,\n",
    "                      shuffle=True,\n",
    "                      skip_header_lines=0,\n",
    "                      batch_size=64):\n",
    "  \n",
    "  filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs, shuffle=shuffle)\n",
    "  reader = tf.TextLineReader(skip_header_lines=skip_header_lines)\n",
    "\n",
    "  _, rows = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "\n",
    "  features = parse_csv(rows)\n",
    "\n",
    "  if shuffle:\n",
    "    features = tf.train.shuffle_batch(\n",
    "        features,\n",
    "        batch_size,\n",
    "        min_after_dequeue=2 * batch_size + 1,\n",
    "        capacity=batch_size * 10,\n",
    "        num_threads=multiprocessing.cpu_count(),\n",
    "        enqueue_many=True,\n",
    "        allow_smaller_final_batch=True\n",
    "    )\n",
    "  else:\n",
    "    features = tf.train.batch(\n",
    "        features,\n",
    "        batch_size,\n",
    "        capacity=batch_size * 10,\n",
    "        num_threads=multiprocessing.cpu_count(),\n",
    "        enqueue_many=True,\n",
    "        allow_smaller_final_batch=True\n",
    "    )\n",
    "\n",
    "  return features, features.pop(PREDICTED_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras.python.keras.layers import Dense\n",
    "\n",
    "def generate_model_fn(learning_rate):\n",
    "    \n",
    "    def _model_fn(mode, features, labels):\n",
    "\n",
    "        (length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight) = INPUT_COLUMNS\n",
    "\n",
    "        transformed_columns = [\n",
    "            length, diameter, height, whole_weight, shucked_weight, viscera_weight, shell_weight\n",
    "        ]\n",
    "\n",
    "        inputs = tf.feature_column.input_layer(features, transformed_columns)\n",
    "\n",
    "        first_hidden_layer = Dense(10, activation='relu')(inputs)\n",
    "        second_hidden_layer = Dense(10, activation='relu')(first_hidden_layer)\n",
    "        output_layer = Dense(1, activation='linear')(second_hidden_layer)\n",
    "\n",
    "        if mode in (Modes.PREDICT, Modes.EVAL):\n",
    "          predictions = tf.reshape(output_layer, [-1])\n",
    "          predictions_dict = {\"ages\": predictions}\n",
    "\n",
    "        if mode in (Modes.TRAIN, Modes.EVAL):\n",
    "          loss = tf.losses.mean_squared_error(labels, output_layer)\n",
    "\n",
    "        if mode == Modes.TRAIN:\n",
    "          train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=learning_rate,\n",
    "            optimizer=\"SGD\")\n",
    "        \n",
    "        if mode == Modes.TRAIN:\n",
    "          return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "        if mode == Modes.EVAL:\n",
    "          eval_metric_ops = {\n",
    "              \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "                  tf.cast(labels, tf.float32), predictions)\n",
    "          }\n",
    "          return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "        \n",
    "        if mode == Modes.PREDICT:\n",
    "          export_outputs = {\n",
    "              'prediction': tf.estimator.export.RegressionOutput(predictions)\n",
    "          }\n",
    "          return tf.estimator.EstimatorSpec(\n",
    "              mode, predictions=predictions_dict, export_outputs=export_outputs)\n",
    "    \n",
    "    return _model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section encapsulates producing the Experiment.  Note that this follows standard practice for tf.contrib.learn of providing data via input_fn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_experiment_fn(**experiment_args):  \n",
    "  \n",
    "  def _experiment_fn(run_config, hparams):\n",
    "\n",
    "    train_input = lambda: generate_input_fn(\n",
    "      hparams.train_files,\n",
    "      num_epochs=hparams.num_epochs,\n",
    "      batch_size=hparams.train_batch_size,\n",
    "    )\n",
    "\n",
    "    test_input = lambda: generate_input_fn(\n",
    "      hparams.eval_files,\n",
    "      shuffle=False\n",
    "    )\n",
    "\n",
    "    return tf.contrib.learn.Experiment(\n",
    "        tf.estimator.Estimator(\n",
    "            generate_model_fn(learning_rate=hparams.learning_rate),\n",
    "            config=run_config\n",
    "        ),\n",
    "        train_input_fn=train_input,\n",
    "        eval_input_fn=test_input,\n",
    "        **experiment_args\n",
    "    )\n",
    "  \n",
    "  return _experiment_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def example_serving_input_fn():\n",
    "  \"\"\"Build the serving inputs.\"\"\"\n",
    "  example_bytestring = tf.placeholder(\n",
    "      shape=[None],\n",
    "      dtype=tf.string,\n",
    "  )\n",
    "  features = tf.parse_example(\n",
    "      example_bytestring,\n",
    "      tf.feature_column.make_parse_example_spec(INPUT_COLUMNS)\n",
    "  )\n",
    "  return tf.estimator.export.ServingInputReceiver(\n",
    "      features, {'example_proto': example_bytestring})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section adds a main method to our code because when we come to run this on CMLE we will change from Datalab to script files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'abalone_output', '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd72acd5150>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_session_config': None}\n",
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:268: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into abalone_output/model.ckpt.\n",
      "INFO:tensorflow:loss = 38.4861, step = 1\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-17:36:58\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-17:37:00\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 115.704, rmse = 10.7566\n",
      "INFO:tensorflow:Validation (step 1): loss = 115.704, global_step = 1, rmse = 10.7566\n",
      "INFO:tensorflow:global_step/sec: 45.5522\n",
      "INFO:tensorflow:loss = 0.681265, step = 101 (2.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.967\n",
      "INFO:tensorflow:loss = 3.89561, step = 201 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.35\n",
      "INFO:tensorflow:loss = 14.785, step = 301 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.362\n",
      "INFO:tensorflow:loss = 2.13239, step = 401 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.66\n",
      "INFO:tensorflow:loss = 0.28721, step = 501 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 576.279\n",
      "INFO:tensorflow:loss = 0.0200672, step = 601 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.807\n",
      "INFO:tensorflow:loss = 12.938, step = 701 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.261\n",
      "INFO:tensorflow:loss = 7.86375, step = 801 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.27\n",
      "INFO:tensorflow:loss = 7.1422, step = 901 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.548\n",
      "INFO:tensorflow:loss = 54.6097, step = 1001 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.366\n",
      "INFO:tensorflow:loss = 0.00274612, step = 1101 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 588.214\n",
      "INFO:tensorflow:loss = 7.42348, step = 1201 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.088\n",
      "INFO:tensorflow:loss = 8.46992, step = 1301 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.382\n",
      "INFO:tensorflow:loss = 0.036822, step = 1401 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.482\n",
      "INFO:tensorflow:loss = 10.3382, step = 1501 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.672\n",
      "INFO:tensorflow:loss = 0.177646, step = 1601 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.304\n",
      "INFO:tensorflow:loss = 25.5104, step = 1701 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.988\n",
      "INFO:tensorflow:loss = 4.23445, step = 1801 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.656\n",
      "INFO:tensorflow:loss = 6.47649, step = 1901 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.879\n",
      "INFO:tensorflow:loss = 13.8211, step = 2001 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.469\n",
      "INFO:tensorflow:loss = 3.27904, step = 2101 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.094\n",
      "INFO:tensorflow:loss = 1.74617, step = 2201 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.995\n",
      "INFO:tensorflow:loss = 1.88256, step = 2301 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.646\n",
      "INFO:tensorflow:loss = 0.257681, step = 2401 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.272\n",
      "INFO:tensorflow:loss = 1.02665, step = 2501 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.365\n",
      "INFO:tensorflow:loss = 0.0235651, step = 2601 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.027\n",
      "INFO:tensorflow:loss = 1.73819, step = 2701 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 611.927\n",
      "INFO:tensorflow:loss = 10.1507, step = 2801 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 567.808\n",
      "INFO:tensorflow:loss = 0.930142, step = 2901 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.406\n",
      "INFO:tensorflow:loss = 17.4942, step = 3001 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.397\n",
      "INFO:tensorflow:loss = 2.67156, step = 3101 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.585\n",
      "INFO:tensorflow:loss = 1.83345, step = 3201 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.268\n",
      "INFO:tensorflow:loss = 0.217575, step = 3301 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.992\n",
      "INFO:tensorflow:loss = 1.61645, step = 3401 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 597.564\n",
      "INFO:tensorflow:loss = 0.444718, step = 3501 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.643\n",
      "INFO:tensorflow:loss = 0.114558, step = 3601 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.063\n",
      "INFO:tensorflow:loss = 0.0823026, step = 3701 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.416\n",
      "INFO:tensorflow:loss = 0.791978, step = 3801 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.458\n",
      "INFO:tensorflow:loss = 1.75547, step = 3901 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.72\n",
      "INFO:tensorflow:loss = 2.89119, step = 4001 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 583.914\n",
      "INFO:tensorflow:loss = 0.0511106, step = 4101 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.486\n",
      "INFO:tensorflow:loss = 7.84831, step = 4201 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 587.834\n",
      "INFO:tensorflow:loss = 28.4807, step = 4301 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.799\n",
      "INFO:tensorflow:loss = 2.08712, step = 4401 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.033\n",
      "INFO:tensorflow:loss = 4.59479, step = 4501 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 580.953\n",
      "INFO:tensorflow:loss = 0.133423, step = 4601 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 597.293\n",
      "INFO:tensorflow:loss = 14.3644, step = 4701 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.504\n",
      "INFO:tensorflow:loss = 2.21447, step = 4801 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.141\n",
      "INFO:tensorflow:loss = 2.61776, step = 4901 (0.175 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into abalone_output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.575315.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-02-17:37:09\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-02-17:37:12\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, loss = 6.29564, rmse = 2.50911\n",
      "INFO:tensorflow:Restoring parameters from abalone_output/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: abalone_output/export/Servo/1501695432/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "from tensorflow.contrib.learn.python.learn.utils import (\n",
    "    saved_model_export_utils)\n",
    "from tensorflow.contrib.training.python.training import hparam\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Input Arguments\n",
    "    parser.add_argument(\n",
    "        '--train-files',\n",
    "        help='GCS or local paths to training data',\n",
    "        nargs='+',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--num-epochs',\n",
    "        help=\"\"\"\\\n",
    "        Maximum number of training data epochs on which to train.\n",
    "        If both --max-steps and --num-epochs are specified,\n",
    "        the training job will run for --max-steps or --num-epochs,\n",
    "        whichever occurs first. If unspecified will run for --max-steps.\\\n",
    "        \"\"\",\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train-batch-size',\n",
    "        help='Batch size for training steps',\n",
    "        type=int,\n",
    "        default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-batch-size',\n",
    "        help='Batch size for evaluation steps',\n",
    "        type=int,\n",
    "        default=1\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-files',\n",
    "        help='GCS or local paths to evaluation data',\n",
    "        nargs='+',\n",
    "        required=True\n",
    "    )\n",
    "    # Training arguments\n",
    "    parser.add_argument(\n",
    "        '--learning-rate',\n",
    "        help='Learning rate for the optimizer',\n",
    "        default=0.001,\n",
    "        type=float\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help='GCS location to write checkpoints and export models',\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--verbosity',\n",
    "        choices=[\n",
    "            'DEBUG',\n",
    "            'ERROR',\n",
    "            'FATAL',\n",
    "            'INFO',\n",
    "            'WARN'\n",
    "        ],\n",
    "        default='INFO',\n",
    "        help='Set logging verbosity'\n",
    "    )\n",
    "    # Experiment arguments\n",
    "    parser.add_argument(\n",
    "        '--eval-delay-secs',\n",
    "        help='How long to wait before running first evaluation',\n",
    "        default=10,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--min-eval-frequency',\n",
    "        help='Minimum number of training steps between evaluations',\n",
    "        default=1,\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--train-steps',\n",
    "        help=\"\"\"\\\n",
    "        Steps to run the training job for. If --num-epochs is not specified,\n",
    "        this must be. Otherwise the training job will run indefinitely.\\\n",
    "        \"\"\",\n",
    "        type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--eval-steps',\n",
    "        help=\"\"\"\\\n",
    "        Number of steps to run evalution for at each checkpoint.\n",
    "        If unspecified will run until the input from --eval-files is exhausted\n",
    "        \"\"\",\n",
    "        default=None,\n",
    "        type=int\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args([\n",
    "        '--train-files', 'gs://smiling-beaming-abalone/abalone_train.csv',\n",
    "        '--eval-files', 'gs://smiling-beaming-abalone/abalone_test.csv',\n",
    "        '--job-dir', 'abalone_output',\n",
    "        '--train-steps', '5000',\n",
    "        '--eval-steps', '100'\n",
    "      ])\n",
    "    \n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    # Set python level verbosity\n",
    "    tf.logging.set_verbosity(args.verbosity)\n",
    "    # Set C++ Graph Execution level verbosity\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = str(\n",
    "        tf.logging.__dict__[args.verbosity] / 10)\n",
    "\n",
    "    # Run the training job\n",
    "    # learn_runner pulls configuration information from environment\n",
    "    # variables using tf.learn.RunConfig and uses this configuration\n",
    "    # to conditionally execute Experiment, or param server code\n",
    "    learn_runner.run(\n",
    "        generate_experiment_fn(\n",
    "            min_eval_frequency=args.min_eval_frequency,\n",
    "            eval_delay_secs=args.eval_delay_secs,\n",
    "            train_steps=args.train_steps,\n",
    "            eval_steps=args.eval_steps,\n",
    "            export_strategies=[saved_model_export_utils.make_export_strategy(\n",
    "                example_serving_input_fn,\n",
    "                exports_to_keep=1\n",
    "            )]\n",
    "        ),\n",
    "        run_config=tf.contrib.learn.RunConfig(model_dir=args.job_dir),\n",
    "        hparams=hparam.HParams(**args.__dict__)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
